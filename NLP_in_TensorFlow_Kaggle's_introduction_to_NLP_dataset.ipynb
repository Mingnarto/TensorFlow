{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_in_TensorFlow-Kaggle's_introduction_to_NLP_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOW0y8XtpGMpu4n1uvmr9T1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mingnarto/TensorFlow/blob/main/NLP_in_TensorFlow_Kaggle's_introduction_to_NLP_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoDqy-eDJq2d"
      },
      "source": [
        "# NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i__0uKgFLzK"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hRFP_WaFRwZ",
        "outputId": "2b871eea-ed37-44c7-c5ad-b19dcc34861c"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-a6b2a096-7e22-ff8d-b9bd-812746a7e56b)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Navoh7FUhJ"
      },
      "source": [
        "## Get a helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCA5LzZEFbxB",
        "outputId": "07e04f3d-b285-45f3-cb70-cd68c77bd4ed"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-15 06:54:57--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-15 06:54:57 (92.2 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07sdfJHcPcwp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import random\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import io\n",
        "import tensorflow_hub as hub\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibtZd2LIFsQK"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (txt samples of Tweets labelled as disaster or not disaster).\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QLgvH6PGJLK",
        "outputId": "c665d128-d090-479f-da62-5191b7d8f875"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-15 06:55:00--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.2.112, 172.253.62.128, 172.253.115.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.2.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-07-15 06:55:00 (103 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOdQEvsLLSWy"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-GWqpgyeLxzB",
        "outputId": "b16d96d9-c0bb-4596-8803-50171f8a986f"
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4CP20lEhMmsw",
        "outputId": "083fffec-a17d-49f1-861b-81f782a8a214"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2RqeKQ8xMrmP",
        "outputId": "2ef38074-48d1-4426-f080-5bc7c84b078e"
      },
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m6LOY65NIZx",
        "outputId": "b65e242b-3b08-4a11-fdba-852f5f97bc91"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMzWIPy-NPnQ",
        "outputId": "4ad0cd16-6af8-4df9-8d8b-b03c063511ca"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UbKy_eKNnhR",
        "outputId": "0a526dea-cdec-4bd4-eee2-f9965cd570b5"
      },
      "source": [
        "# Let's visualize some random training samples\n",
        "random_index = random.randint(0, len(train_df)-5)  # Create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f'Target:', '(real disaster)' if target > 0 else '(not real disaster)')\n",
        "  print(f'Text:\\n{text}\\n')\n",
        "  print('---\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: (real disaster)\n",
            "Text:\n",
            "Heavy rain frequent thunder and gusty winds moving into parts of Uptown and Midtown. http://t.co/KQJevYqzLV - CN http://t.co/HmWhob7prs\n",
            "\n",
            "---\n",
            "\n",
            "Target: (real disaster)\n",
            "Text:\n",
            "@modnao23 the hail is ruining everything. Plus my car I haven't even gotten yet. Have yet another killer migraine and I lost my glasses. ??\n",
            "\n",
            "---\n",
            "\n",
            "Target: (real disaster)\n",
            "Text:\n",
            "BBC Forced To Retract False Claims About Cyclone Pam http://t.co/ciHC8Nrc9h via @wordpressdotcom\n",
            "\n",
            "---\n",
            "\n",
            "Target: (not real disaster)\n",
            "Text:\n",
            "Super sweet and beautiful :) https://t.co/TUi9uwBvVp\n",
            "\n",
            "---\n",
            "\n",
            "Target: (real disaster)\n",
            "Text:\n",
            "RT_America: RT RT_com: Eye of Super Typhoon Soudelor seen from space (TIME-LAPSE) https://t.co/FC3BxRtHPG http://t.co/BIU4koWGlz\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71O9ISziOpE6"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRghj_ZVPW8h"
      },
      "source": [
        "# use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size=0.1,  # use 10% of training data for validation split\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix1xTIRgQMEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f64440b-8363-4e8f-ccb1-fdee8c9f7ef5"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dVWelrrQYCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa069d1-88d4-4e13-b476-68492e5f0610"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x38KosutQfH4"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "- Tokenization - direct mapping of token (a token could be a word or a charcater) to number\n",
        "- Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjBeiHTYWpsX"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Cm9KYOY3i1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d9f69f-01d0-46b4-8d6e-1f9ec161a037"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYSo6h6RY6sP"
      },
      "source": [
        "# Use the deafult TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None,  # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    split='whitespace',\n",
        "                                    ngrams=None,  # create groups of n-words?\n",
        "                                    output_mode='int',  # how to map tokens numbers\n",
        "                                    output_sequence_length=None,  # how long do you want your sequences to be\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfkoJgpLa7Mm",
        "outputId": "37e4dd00-bcd8-40b5-af09-78307c5eb45e"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJD-01HEbWKv"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000  # max number of words to have in our vocabulary\n",
        "max_length = 15  # max length our sequences will be (e.g. how many words from a Tweet does a model see), means if the number of words is 30 the model will only look until 15\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_MWLdUZcm3F"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sORruwAddGbo",
        "outputId": "426cd686-f28e-4e86-f946-d51680073aa5"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onF9p2l9dX28",
        "outputId": "221ec9e7-6a15-4b19-8f66-d67898930a1f"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text:\\n {random_sentence})\\n\\nVentorized version:')\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " #hot  C-130 specially modified to land in a stadium and rescue hostages in Iran in 1980 http://t.co/6ioaBSl6I7 #prebreak #best)\n",
            "\n",
            "Ventorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 175, 1544, 1359, 1501,    5,  481,    4,    3, 1358,    7,  389,\n",
              "         422,    4,  458,    4]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux894Um4eC03",
        "outputId": "5f53edb6-3793-4383-ad0b-9236d795a7ef"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()  # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5]  # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:]  # get the least common words\n",
        "print(f'Number of words in vocab: {len(words_in_vocab)}')\n",
        "print(f'5 most common words: {top_5_words}')\n",
        "print(f'5 least common words: {bottom_5_words}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIqgZelPhc7F"
      },
      "source": [
        "### Creating an Embedding using an Embedding layer\n",
        "\n",
        "To mekae our embedding, we're going to use TensorFlow's embedding layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The parameters we care most aboout for our embedding layer:\n",
        "- `input_dim` = the size of our vocabulary\n",
        "- `output_dim` = the size of the output embedding vecor, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "- `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09aZGqQgseKi",
        "outputId": "2b54d6ea-28b8-46a1-94c1-4083a3c939a4"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=max_vocab_length,  # set input shape\n",
        "                             output_dim=128,  # output shape\n",
        "                             embeddings_initializer='uniform',\n",
        "                             input_length=max_length)  # how long is each input\n",
        "\n",
        "embedding                     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7fc7c65bce50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI4qw9sCs4gK",
        "outputId": "96c61469-b449-4b98-d0e7-36f6543b8705"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text:\\n {random_sentence}\\\n",
        "        \\n\\nEmbedded version:')\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " .@RaniaKhalek true. I faced everything from 'Is Bin Laden your uncle?' to 'Hopefully Afghanistan will be bombed'. Children can be very ugly.        \n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.00907751, -0.03253768, -0.03205167, ...,  0.03204106,\n",
              "         -0.02514553, -0.00850205],\n",
              "        [ 0.02665557, -0.00293163,  0.02084608, ..., -0.00727965,\n",
              "         -0.00497506, -0.02698405],\n",
              "        [ 0.0132792 , -0.02959605,  0.01290934, ..., -0.04351696,\n",
              "         -0.03318029, -0.01681866],\n",
              "        ...,\n",
              "        [-0.00692635, -0.04372942, -0.00313397, ...,  0.02406584,\n",
              "          0.03707721,  0.04303179],\n",
              "        [-0.02942356, -0.04989276,  0.000212  , ..., -0.04314805,\n",
              "          0.02044905,  0.00123969],\n",
              "        [-0.00961908,  0.02992492, -0.0437938 , ..., -0.0481127 ,\n",
              "         -0.0051545 ,  0.00116838]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZUkl0F3tqxq",
        "outputId": "4922cc01-70ae-4772-f2a7-1afe05e29c93"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-9.07751173e-03, -3.25376764e-02, -3.20516713e-02, -3.36058512e-02,\n",
              "        -4.40988541e-02,  3.17324437e-02,  1.36599652e-02, -3.63294035e-03,\n",
              "        -1.51820891e-02, -4.65544239e-02, -1.72449835e-02, -4.77869622e-02,\n",
              "        -2.15860251e-02, -2.46007089e-02,  2.72012837e-02,  2.05592178e-02,\n",
              "        -4.34371717e-02,  8.57336447e-03,  3.59299295e-02, -4.18154486e-02,\n",
              "        -3.15060616e-02,  1.10308528e-02,  3.49225663e-02, -4.08305041e-02,\n",
              "        -1.14940032e-02,  2.98130848e-02, -2.52237562e-02, -7.53403828e-03,\n",
              "        -1.00253448e-02, -3.78877521e-02,  2.43082754e-02,  3.46103944e-02,\n",
              "        -3.74933332e-03, -2.06743237e-02,  4.10194732e-02,  3.06963921e-03,\n",
              "        -3.66640799e-02,  1.04401931e-02, -1.17086880e-02,  3.79046686e-02,\n",
              "        -6.28441572e-03,  2.36301161e-02, -7.38938898e-03,  2.73268856e-02,\n",
              "         2.43773311e-03,  1.33432038e-02,  5.05480915e-03,  1.59884207e-02,\n",
              "         4.28546704e-02,  2.73475312e-02,  3.70199196e-02, -2.33213659e-02,\n",
              "         3.59062813e-02,  1.06984377e-03,  1.53154619e-02,  3.90842892e-02,\n",
              "        -1.06368177e-02,  4.74480875e-02,  2.62312032e-02,  3.42080928e-02,\n",
              "         1.42622106e-02, -3.54369991e-02, -4.75840457e-02, -1.40175335e-02,\n",
              "        -3.91080230e-03, -9.58312675e-03, -1.70482881e-02,  6.30484894e-03,\n",
              "         2.49769203e-02,  4.96573932e-02,  4.32786085e-02,  1.26815178e-02,\n",
              "         3.87091152e-02, -3.97927873e-02,  2.35664286e-02,  1.04612485e-02,\n",
              "        -7.14552402e-03,  1.25938915e-02, -3.67097259e-02,  2.91824453e-02,\n",
              "         3.21237557e-02, -6.54796511e-03,  3.17812450e-02, -2.40847226e-02,\n",
              "         4.41946499e-02,  4.22121026e-02, -1.16593242e-02,  4.10412811e-02,\n",
              "        -9.44361091e-05,  4.18973677e-02, -4.54171672e-02,  7.41847605e-03,\n",
              "        -3.77228856e-02, -1.34092681e-02,  3.73869054e-02, -1.94296986e-03,\n",
              "         1.63301565e-02,  1.85145847e-02,  1.01125836e-02,  2.68999822e-02,\n",
              "        -4.85241301e-02,  9.66334343e-03, -5.13847917e-03, -2.48675477e-02,\n",
              "        -2.87612807e-02, -2.09995266e-02,  2.20148079e-02,  1.27144940e-02,\n",
              "         3.14994901e-03,  7.66811520e-03, -2.97379252e-02,  9.92937014e-03,\n",
              "        -1.93526875e-02, -3.24196741e-03, -2.84088776e-03, -1.45987980e-02,\n",
              "         3.36487405e-02, -1.64322853e-02, -2.91200411e-02,  1.67766549e-02,\n",
              "         2.98738480e-03, -3.16227078e-02, -3.21257934e-02, -2.39345320e-02,\n",
              "        -1.85118206e-02,  3.20410617e-02, -2.51455307e-02, -8.50205496e-03],\n",
              "       dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " \".@RaniaKhalek true. I faced everything from 'Is Bin Laden your uncle?' to 'Hopefully Afghanistan will be bombed'. Children can be very ugly.\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr0_m0opuFPJ"
      },
      "source": [
        "## Modeling a text dataset (running a series of experimentats)\n",
        "\n",
        "Now we've got way to turn our text sequences into numbers, it's time to start building a series of modeling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "- Model 0: Naive Bayes (baseline), this is from Sklearn ML map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "- Model 1: Feed-forward neural network (dense model_\n",
        "- Model 2: LSTM model (RNN)\n",
        "- Model 3: GRU model (RNN)\n",
        "- Model 4: Bidirectional Neural Network (RNN)\n",
        "- Model 5: 1D Convolutional Neural Network (CNN)\n",
        "- Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learrning for NLP)\n",
        "- Model 7: Same as model 6 with 100% of training data\n",
        "\n",
        "How are we going to approach all of these?\n",
        "\n",
        "Use the standard steps in modeling steps:\n",
        "- Create a model\n",
        "- Build a model\n",
        "- Fit a model\n",
        "- Evaluate our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS8rNSwXzaMJ"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modeling experiments, it's important to create a baseline model so you've got a benchmark for futeure experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using TF-IDF formula to convert our words to numbers\n",
        "\n",
        "> **NOTE:** It's common practice to use non-DL algorithms as a baseline because as a baseline because of their speed and then later using DL to see if you can improve upon them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOIVA5iO8HLe",
        "outputId": "5f652393-3a40-4b96-e90b-9dc64f722dc9"
      },
      "source": [
        "# Create tokenization and modeling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    ('tfidf', TfidfVectorizer()),  # convert words to numbers using tfidf\n",
        "                    ('clf', MultinomialNB())  # model the text (clf == classifier)\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE8M9fFEEkui",
        "outputId": "b855bed2-4d1f-4ddf-ea76-745f57d9eeef"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f'Our baseline model achieves an accuracy of: {baseline_score*100:.2f}&')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27&\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkTu5fTJE2iq",
        "outputId": "963e139d-8a5c-4ff2-9060-0c6fabe68220"
      },
      "source": [
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z6BNFoBcqAn",
        "outputId": "218d7c6c-3ab7-4a48-9725-1e1cde7b00f1"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHrLQtrXc1YP"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's predictions with different metrics every time, however, this will be cumbersome and can be easily fixed with a function.\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1-score\n",
        "\n",
        "> For a deep overview of many different methods, see the Sklearn documentation: https://colab.research.google.com/drive/1UKkJe16LFi4ZfQRfbxze6236vn5bzafU#scrollTo=b5kQos0ed4Zg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5kQos0ed4Zg"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "def calculate_results(y_true, y_pred):\n",
        "  '''\n",
        "  calculates model accuracy, precision, recall and f1-score of a binary classification model.\n",
        "  '''\n",
        "  # Calsulate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1-score using 'weighted' average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "  model_results = {'accuracy': model_accuracy,\n",
        "                   'precision': model_precision,\n",
        "                   'recall': model_recall,\n",
        "                   'f1': model_f1}\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZobSDfRugGFa",
        "outputId": "939e478f-c3b3-47ef-cedb-3c039b81a0bb"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7njgv7SQgUWg"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opfj143nk6ya"
      },
      "source": [
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = 'model_logs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBtgsvE7lbU4"
      },
      "source": [
        "# Build model with the FUnctional API\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)  # input are 1-dimensional strings\n",
        "x = text_vectorizer(inputs)  # turn the input text into numbers\n",
        "x = embedding(x)  # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x)  # condense the feature vector for each token to one vector\n",
        "#x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)  # create the output layer, want binary oututs so use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_dense')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpN6QLZlqKaO",
        "outputId": "36e750f0-ad1a-4d55-c711-8c2d6a5908ea"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9_pYPAPnEhj",
        "outputId": "ec573b33-a339-411f-ecdb-3a1726c5ab92"
      },
      "source": [
        "model_1.summary()  # old summary (without GlobalAveragePooling1D)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MMkeLfxnSQZ"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAT6JC0rnnYL",
        "outputId": "cdc8d0b4-5f3d-45bf-a2aa-2a6b463b3eb5"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name='model_1_dense')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210715-065509\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 24ms/step - loss: 0.6138 - accuracy: 0.6971 - val_loss: 0.5387 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.4430 - accuracy: 0.8194 - val_loss: 0.4704 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.3477 - accuracy: 0.8599 - val_loss: 0.4563 - val_accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2852 - accuracy: 0.8921 - val_loss: 0.4667 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2378 - accuracy: 0.9132 - val_loss: 0.4773 - val_accuracy: 0.7782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNRIILu5qwo5",
        "outputId": "dba0812e-9f44-42ff-fe56-ea7f0133208c"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4772835373878479, 0.778215229511261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swTiPCy1oeEj",
        "outputId": "7d3ab541-e0b7-4a12-d6ef-b7fe959f2c0e"
      },
      "source": [
        "# Check the results (old)\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4772835373878479, 0.778215229511261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NiunJcOphRC",
        "outputId": "b8dcb827-f3fa-4878-eec6-907266a94e4c"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bACttq38pnu6",
        "outputId": "20225901-4663-4fe7-aec7-2cede7afcc2c"
      },
      "source": [
        "# Look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4061289], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhxvWAfwrlEz",
        "outputId": "b1381590-3b96-448d-9005-8b14c8664686"
      },
      "source": [
        "# Look at the first 10 predictions\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4061289 ],\n",
              "       [0.80760115],\n",
              "       [0.9980299 ],\n",
              "       [0.12432486],\n",
              "       [0.10916305],\n",
              "       [0.93406355],\n",
              "       [0.93002963],\n",
              "       [0.9940824 ],\n",
              "       [0.9703766 ],\n",
              "       [0.3057091 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN0sC_Bnrqrk",
        "outputId": "30b12596-0f6d-4f76-e73e-e24c180ee052"
      },
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLloaEEasXt_",
        "outputId": "5c025392-3449-4db9-f9a6-4136e9a312cf"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'f1': 0.7758810170952618,\n",
              " 'precision': 0.7807522349051432,\n",
              " 'recall': 0.7782152230971129}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVZuWsMwu9TG",
        "outputId": "5eb6bd68-d8eb-4ae1-d222-fa34ae78f5bd"
      },
      "source": [
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpZ6ffuUvxvP"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hyXH0WAxFLf",
        "outputId": "4a10a373-35a7-4a04-d45b-be4e095fc364"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTEJDW1uxVKO",
        "outputId": "d627064a-a228-41e2-ac12-fc678acb9417"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRTxRuETxjaN",
        "outputId": "cea12220-6c0d-4768-8869-15c1377307f4"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data, which have been learned for ~5 epochs)\n",
        "embed_weights = model_1.get_layer('embedding').get_weights()\n",
        "embed_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.04590741, -0.0299396 ,  0.03558392, ..., -0.0280385 ,\n",
              "         -0.06216237,  0.04303638],\n",
              "        [-0.01177409, -0.02437172, -0.04245682, ..., -0.00957391,\n",
              "         -0.04097467,  0.03138991],\n",
              "        [ 0.04032651, -0.0097938 , -0.01991646, ...,  0.04531282,\n",
              "          0.00649192,  0.00683686],\n",
              "        ...,\n",
              "        [ 0.03307874,  0.02977545,  0.01374917, ..., -0.01520012,\n",
              "          0.04286638,  0.04215838],\n",
              "        [-0.08403958,  0.05443313,  0.08289906, ..., -0.05052716,\n",
              "         -0.01649883,  0.04637718],\n",
              "        [-0.05943283,  0.04435625,  0.04476077, ..., -0.03533433,\n",
              "         -0.02061126,  0.06952292]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgNgfMtvyGeO",
        "outputId": "e5199c14-c78c-4d0d-f644-d0e335b06d56"
      },
      "source": [
        "# Shape of embedding layer\n",
        "embed_weights_shape = model_1.get_layer('embedding').get_weights()[0]\n",
        "print(embed_weights_shape.shape)  # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dxrutnDypt1"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: https://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DkTGIM3z6Cu"
      },
      "source": [
        "# Create embedding files (we've got this from TensorFlow's word wmbeddings documentation)\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights_shape[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Qf16Vd0hZm"
      },
      "source": [
        "# Download files from Colab to upload to projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   #files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "#   pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeT9GJEEH_xc"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent network is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "> **Resources:** If you want an overview of the internals of a recurrent neural network, see the following:\n",
        "- MIT's sequence modeling lecture https://youtu.be/qjrad0V0uJE\n",
        "- Chris Olah's intro to LSTM's: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "- Andrej Karpathy's the unreasonable effectiveness of recurrent neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-nYjD7j5Wi1"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = Long Short Term Memory (one of the most popular LSTM sells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJUymg9YQtWK"
      },
      "source": [
        "# Create an LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(units=64, return_sequences=True)(x)  # when you're stacking RNN celss together, you need to set return_sequences=True\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64, activation='relu')(x)\n",
        "#print(x.shape)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='model_2_LSTM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3ND4KxMRxxs",
        "outputId": "23b194a5-0226-4f19-bbd5-481e71aef12e"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlwueYHHjcIb"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kQ1wT4ljo5a",
        "outputId": "b40efbc3-bf9a-4d23-ea41-c9bd9645e03c"
      },
      "source": [
        "# Fit the model\n",
        "history_model_2 = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_2_LSTM')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210715-065554\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 26ms/step - loss: 0.2230 - accuracy: 0.9241 - val_loss: 0.5294 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1596 - accuracy: 0.9415 - val_loss: 0.6414 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.1287 - accuracy: 0.9529 - val_loss: 0.6396 - val_accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1081 - accuracy: 0.9593 - val_loss: 0.7120 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0877 - accuracy: 0.9650 - val_loss: 0.8789 - val_accuracy: 0.7756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5WP2QRrj8FN",
        "outputId": "16c3977f-cb3a-4917-c7a5-0c48b10f9681"
      },
      "source": [
        "# Make predictions with LSTM\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0141405e-02],\n",
              "       [8.8653791e-01],\n",
              "       [9.9976426e-01],\n",
              "       [3.6397189e-02],\n",
              "       [9.6726144e-04],\n",
              "       [9.9851829e-01],\n",
              "       [9.0299141e-01],\n",
              "       [9.9980551e-01],\n",
              "       [9.9969530e-01],\n",
              "       [3.9869609e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwRT5lO0kDzS",
        "outputId": "6adbf203-d073-496f-9465-d9b9bc088310"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS8VzCL3kQW7",
        "outputId": "a14d4488-a432-498f-8585-69efb0bd8fb0"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'f1': 0.7733619560087615,\n",
              " 'precision': 0.7777490986405654,\n",
              " 'recall': 0.7755905511811023}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_ifiPBgkbtL",
        "outputId": "9a6170ee-aeb7-4255-f2aa-b0fa95bd4f1c"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8rfTVRakfXi"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or Gated Recurrent UnicodeTranslateError\n",
        "\n",
        "The Grue cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66nk_2aRlyoD"
      },
      "source": [
        "# Build and RNN using GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.GRU(64, return_sequences=True)(x)  # if you want to stack layers on top of each other, you need return_sequences = True\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(42, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(99)(x)\n",
        "# print(x.shape)\n",
        "#x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name='model_3_GRU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQR__OF9o25n",
        "outputId": "76357b96-1cdf-452e-e2c1-c9de9f132bd9"
      },
      "source": [
        "# Get a summary\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2PNAaSTsLht"
      },
      "source": [
        "# Compile the model\n",
        "model_3. compile(loss='binary_crossentropy',\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP4bGjeevpJO",
        "outputId": "d60a7345-2a9f-4173-9fee-6f66e51b3078"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_3_GRU')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20210715-065637\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.1608 - accuracy: 0.9365 - val_loss: 0.7710 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0861 - accuracy: 0.9686 - val_loss: 0.7884 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0715 - accuracy: 0.9720 - val_loss: 0.8908 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0609 - accuracy: 0.9736 - val_loss: 1.1446 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0557 - accuracy: 0.9774 - val_loss: 1.0954 - val_accuracy: 0.7835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ_-pyKuwWbJ",
        "outputId": "d44af36a-80a3-48a5-c53a-ea6ff90662ed"
      },
      "source": [
        "# Make some predictions with our model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.3176829e-03],\n",
              "       [8.3893108e-01],\n",
              "       [9.9985433e-01],\n",
              "       [1.1884013e-01],\n",
              "       [1.1297951e-04],\n",
              "       [9.9973720e-01],\n",
              "       [8.0875164e-01],\n",
              "       [9.9991655e-01],\n",
              "       [9.9989569e-01],\n",
              "       [8.3434665e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaHo0kE6wgBY",
        "outputId": "0ccc3f3a-a558-42b3-98ba-8f859d4a406e"
      },
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seUss0gKwsu_",
        "outputId": "bf08beec-a1d8-434b-e97d-a1daddc4c77e"
      },
      "source": [
        "# Calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.34645669291339,\n",
              " 'f1': 0.7817956468843655,\n",
              " 'precision': 0.7847784624516524,\n",
              " 'recall': 0.7834645669291339}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euxsgKSxw4H3"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidirectional RNN goes from right to left as well as left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOtnFKb11IzI"
      },
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "#print(x.shape)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name='model_4_bidirectional')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwj3yw4RCF7c",
        "outputId": "097e1984-78a2-4675-a192-6e01304f747d"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk3ub2cHCMk7"
      },
      "source": [
        "# Compile the model\n",
        "model_4.compile (loss='binary_crossentropy',\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FOlQ00uC-B9",
        "outputId": "774d238b-8c20-4a24-eb1e-ef9f07f40f87"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_4_bidirectional')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210715-065722\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 28ms/step - loss: 0.1038 - accuracy: 0.9721 - val_loss: 0.8819 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0535 - accuracy: 0.9768 - val_loss: 1.1456 - val_accuracy: 0.7651\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.0472 - accuracy: 0.9783 - val_loss: 1.2567 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0422 - accuracy: 0.9804 - val_loss: 1.4572 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0561 - accuracy: 0.9761 - val_loss: 1.2641 - val_accuracy: 0.7743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X1gWfGnDT9O",
        "outputId": "3efbdb02-0d53-413c-ac51-b3dc1109445a"
      },
      "source": [
        "# Make predictions with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5054409e-03],\n",
              "       [6.6763967e-01],\n",
              "       [9.9965453e-01],\n",
              "       [1.8117182e-01],\n",
              "       [2.2515449e-05],\n",
              "       [9.9916315e-01],\n",
              "       [6.6384822e-01],\n",
              "       [9.9996829e-01],\n",
              "       [9.9987614e-01],\n",
              "       [9.8111594e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t12DBlCPDiMr",
        "outputId": "0440e5cd-2659-4b62-e486-c8586fccc3a6"
      },
      "source": [
        "# Convert pred probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7i1FjE_DxoZ",
        "outputId": "69229ee6-3b0b-475a-b56a-4713705fccd0"
      },
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'f1': 0.7729333240681188,\n",
              " 'precision': 0.7747317935775544,\n",
              " 'recall': 0.7742782152230971}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBnookHsEEGM"
      },
      "source": [
        "## Convolution Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "We've used CNNs for images but images are typically 2D (height x width)... however, our text data is 1D.\n",
        "\n",
        "Previous we've Conv2D for our image data but now we're going to use Conv1D.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case, text):\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs (class probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ipP2lNUIZzH"
      },
      "source": [
        "## Model 5: Conv1D\n",
        "\n",
        "For different explanations of parameters see:\n",
        "- https://poloclub.github.io/cnn-explainer/ (this is for 2D but can relate to 1D data)\n",
        "- Difference between 'same' and 'valid' padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH7_NLUmIc6Z",
        "outputId": "7da1bff8-0ffd-4f68-e096-fdd429a41d2e"
      },
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "embedding_test = embedding(text_vectorizer(['this is a test sentence']))  # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,  # this is also referred to as ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        strides=1,  # default\n",
        "                        activation='relu',\n",
        "                        padding='valid')  # default = 'valid', the output is smaller than the input shape, 'same' means output is same shape as input\n",
        "conv_1d_output = conv_1d(embedding_test)  # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPooling1D()\n",
        "max_pool_output = max_pool(conv_1d_output)  # equivalent to 'get the most important feature' or 'get the feature with the highest value'\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzCG3FLuKLLo",
        "outputId": "7990b912-4cf6-4158-a440-64a8b61dd64f"
      },
      "source": [
        "embedding_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.02445515,  0.06482767,  0.02868516, ..., -0.04384512,\n",
              "          0.01812091,  0.05473163],\n",
              "        [ 0.06100331,  0.034117  ,  0.02910906, ..., -0.02260356,\n",
              "         -0.00945901, -0.01367901],\n",
              "        [-0.04728117,  0.02588437, -0.03082003, ..., -0.0263982 ,\n",
              "         -0.05506435,  0.01228437],\n",
              "        ...,\n",
              "        [-0.04849482,  0.00067374,  0.00788176, ..., -0.03632676,\n",
              "         -0.02401611,  0.0006143 ],\n",
              "        [-0.04849482,  0.00067374,  0.00788176, ..., -0.03632676,\n",
              "         -0.02401611,  0.0006143 ],\n",
              "        [-0.04849482,  0.00067374,  0.00788176, ..., -0.03632676,\n",
              "         -0.02401611,  0.0006143 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jrc-vx-NtXZ",
        "outputId": "b91088f7-9b60-4062-b478-2b7da63f18f0"
      },
      "source": [
        "conv_1d_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              "array([[[0.01544614, 0.        , 0.05017765, 0.        , 0.        ,\n",
              "         0.02571294, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.02250774, 0.05348108, 0.05891936, 0.        , 0.04179778,\n",
              "         0.00415229, 0.08622937, 0.        , 0.        , 0.        ,\n",
              "         0.07672321, 0.        , 0.02493857, 0.0462534 , 0.01435422,\n",
              "         0.02580136, 0.        , 0.        , 0.04331142, 0.0602425 ,\n",
              "         0.        , 0.04642853],\n",
              "        [0.        , 0.        , 0.02137715, 0.02148406, 0.        ,\n",
              "         0.        , 0.        , 0.03171972, 0.        , 0.0622806 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.03619883, 0.02333844, 0.01851298, 0.02973832, 0.02769117,\n",
              "         0.        , 0.09139614, 0.03199997, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.03082143, 0.        , 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.04653195, 0.01192956, 0.00775001,\n",
              "         0.        , 0.04280306, 0.        , 0.        , 0.02590415,\n",
              "         0.06648014, 0.        , 0.0358967 , 0.00183032, 0.04043584,\n",
              "         0.        , 0.02752719, 0.        , 0.        , 0.10543971,\n",
              "         0.        , 0.07615601, 0.01973365, 0.0261151 , 0.00298074,\n",
              "         0.        , 0.00999602, 0.        , 0.00884882, 0.04184335,\n",
              "         0.01415434, 0.0010643 ],\n",
              "        [0.        , 0.        , 0.02759521, 0.        , 0.        ,\n",
              "         0.01577643, 0.00711904, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.00114892, 0.01997402, 0.02549998,\n",
              "         0.02755452, 0.08244976, 0.        , 0.00731137, 0.11463992,\n",
              "         0.        , 0.09385528, 0.        , 0.00388867, 0.01248596,\n",
              "         0.        , 0.01785871, 0.02664275, 0.00606046, 0.        ,\n",
              "         0.05600414, 0.01555183],\n",
              "        [0.        , 0.        , 0.01269804, 0.        , 0.01323328,\n",
              "         0.        , 0.03230779, 0.        , 0.        , 0.        ,\n",
              "         0.0203087 , 0.        , 0.01481908, 0.01332017, 0.00199372,\n",
              "         0.01602073, 0.        , 0.02484159, 0.        , 0.06534064,\n",
              "         0.        , 0.06223933, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.08010072, 0.0279665 , 0.02102588, 0.        ,\n",
              "         0.06205616, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.00095897, 0.01751968,\n",
              "         0.01076886, 0.01477917, 0.02271605, 0.        , 0.        ,\n",
              "         0.00167537, 0.        , 0.        , 0.00162887, 0.        ,\n",
              "         0.0139186 , 0.00938133, 0.00659056, 0.        , 0.0438407 ,\n",
              "         0.        , 0.01084552, 0.00198964, 0.02107157, 0.        ,\n",
              "         0.        , 0.05009378, 0.        , 0.00887084, 0.        ,\n",
              "         0.        , 0.02043929],\n",
              "        [0.        , 0.        , 0.        , 0.00095897, 0.01751968,\n",
              "         0.01076886, 0.01477918, 0.02271605, 0.        , 0.        ,\n",
              "         0.00167539, 0.        , 0.        , 0.00162887, 0.        ,\n",
              "         0.0139186 , 0.00938133, 0.00659055, 0.        , 0.04384069,\n",
              "         0.        , 0.01084551, 0.00198964, 0.02107157, 0.        ,\n",
              "         0.        , 0.05009378, 0.        , 0.00887084, 0.        ,\n",
              "         0.        , 0.02043928],\n",
              "        [0.        , 0.        , 0.        , 0.00095897, 0.01751967,\n",
              "         0.01076887, 0.01477918, 0.02271605, 0.        , 0.        ,\n",
              "         0.00167538, 0.        , 0.        , 0.00162887, 0.        ,\n",
              "         0.0139186 , 0.00938132, 0.00659055, 0.        , 0.04384069,\n",
              "         0.        , 0.01084551, 0.00198964, 0.02107157, 0.        ,\n",
              "         0.        , 0.05009378, 0.        , 0.00887084, 0.        ,\n",
              "         0.        , 0.02043929],\n",
              "        [0.        , 0.        , 0.        , 0.00095897, 0.01751967,\n",
              "         0.01076886, 0.01477918, 0.02271606, 0.        , 0.        ,\n",
              "         0.00167538, 0.        , 0.        , 0.00162887, 0.        ,\n",
              "         0.0139186 , 0.00938132, 0.00659056, 0.        , 0.04384068,\n",
              "         0.        , 0.01084551, 0.00198964, 0.02107156, 0.        ,\n",
              "         0.        , 0.05009378, 0.        , 0.00887084, 0.        ,\n",
              "         0.        , 0.02043929],\n",
              "        [0.        , 0.        , 0.        , 0.00095897, 0.01751968,\n",
              "         0.01076886, 0.01477918, 0.02271606, 0.        , 0.        ,\n",
              "         0.00167538, 0.        , 0.        , 0.00162887, 0.        ,\n",
              "         0.01391859, 0.00938132, 0.00659056, 0.        , 0.04384068,\n",
              "         0.        , 0.0108455 , 0.00198964, 0.02107157, 0.        ,\n",
              "         0.        , 0.05009378, 0.        , 0.00887084, 0.        ,\n",
              "         0.        , 0.02043929],\n",
              "        [0.        , 0.        , 0.        , 0.00095897, 0.01751968,\n",
              "         0.01076886, 0.01477919, 0.02271606, 0.        , 0.        ,\n",
              "         0.00167539, 0.        , 0.        , 0.00162887, 0.        ,\n",
              "         0.0139186 , 0.00938133, 0.00659056, 0.        , 0.04384068,\n",
              "         0.        , 0.01084551, 0.00198964, 0.02107157, 0.        ,\n",
              "         0.        , 0.05009378, 0.        , 0.00887084, 0.        ,\n",
              "         0.        , 0.02043929]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwUTm2tUNyTf",
        "outputId": "aeab1ddb-944e-401a-8ffa-3e8907e332b4"
      },
      "source": [
        "max_pool_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              "array([[0.01544614, 0.        , 0.05017765, 0.02148406, 0.01751968,\n",
              "        0.02571294, 0.04280306, 0.03171972, 0.        , 0.0622806 ,\n",
              "        0.06648014, 0.05348108, 0.05891936, 0.01997402, 0.04179778,\n",
              "        0.03619883, 0.08622937, 0.02484159, 0.02973832, 0.11463992,\n",
              "        0.07672321, 0.09385528, 0.03199997, 0.0462534 , 0.01435422,\n",
              "        0.02580136, 0.08010072, 0.03082143, 0.04331142, 0.0602425 ,\n",
              "        0.06205616, 0.04642853]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlVYqQIIOBXp",
        "outputId": "464b8b0a-eb9f-4a2b-ebf7-13bdde5441e2"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, strides=1, activation='relu', padding='valid')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "#x = layers.Dense(64, activation='relu)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name='model_5_Conv1D')\n",
        "\n",
        "# Compile the Conv1D\n",
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Get a summary of our Conv1D model\n",
        "model_5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vBLz6cGBzXr",
        "outputId": "377f9a58-490f-47bd-f18b-52043aa6a25e"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_5_conv1D')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_conv1D/20210715-065814\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 22ms/step - loss: 0.1215 - accuracy: 0.9591 - val_loss: 0.8892 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0734 - accuracy: 0.9721 - val_loss: 1.0149 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0616 - accuracy: 0.9768 - val_loss: 1.1107 - val_accuracy: 0.7585\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0541 - accuracy: 0.9783 - val_loss: 1.2136 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0522 - accuracy: 0.9778 - val_loss: 1.2119 - val_accuracy: 0.7585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd3urpUODFq7",
        "outputId": "a6e99996-0632-43b5-dfde-f969145a2e66"
      },
      "source": [
        "# Make some predictions with our Con1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.2288820e-01],\n",
              "       [9.8714441e-01],\n",
              "       [9.9960846e-01],\n",
              "       [3.2328308e-02],\n",
              "       [1.5247774e-07],\n",
              "       [9.9850368e-01],\n",
              "       [9.9151683e-01],\n",
              "       [9.9999106e-01],\n",
              "       [9.9999988e-01],\n",
              "       [9.5387864e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0mTUj1Jf-_",
        "outputId": "dec6e7f5-c0ad-40d8-f0ef-0ef12fe00b8d"
      },
      "source": [
        "# Convert model 5 pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g2SEVbwQ4wh",
        "outputId": "ae94f766-78e4-4464-ec3d-a0585ba5a767"
      },
      "source": [
        "# Evaluate model 5 predictions\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'f1': 0.7577141851857451,\n",
              " 'precision': 0.7581771522804598,\n",
              " 'recall': 0.7585301837270341}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5NqNIooRFTW",
        "outputId": "84d324bb-a662-449f-9cfd-80a6b5104556"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_UrZXItRGne"
      },
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Now we've built a few of our own model, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "See how the USE was created here: https://arxiv.org/abs/1803.11175"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qtrFG5n-YyHo",
        "outputId": "4b70aa32-6c80-4e1b-e14c-365f8a511e02"
      },
      "source": [
        "sample_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There's a flood in my street!\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmGeylIYWqJL",
        "outputId": "f7fdb9fa-5830-4e5f-ce99-8be9ff9548b9"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       'When you can the universal sentence encoder on a sentence, it turns it into numbers.'])\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157027  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680985  0.05589838 -0.01068729 -0.00597292  0.00639323 -0.0181952\n",
            "  0.00030814  0.09105888  0.05874645 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865346 -0.04209305  0.0267898   0.03011008  0.00321069\n",
            " -0.00337971 -0.04787356  0.02266719 -0.00985925 -0.04063613 -0.01292093\n",
            " -0.04666384  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014441\n",
            "  0.02871508  0.04947684 -0.00633978 -0.08960193  0.02807117 -0.00808362\n",
            " -0.01360601  0.0599865  -0.10361787 -0.05195374  0.00232955 -0.0233253\n",
            " -0.03758105  0.03327729], shape=(50,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkJeRxw9YwNb",
        "outputId": "c7e0d1a5-d960-409d-f0d4-89faa37fc081"
      },
      "source": [
        "embed_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.01157027,  0.0248591 ,  0.02878048, ..., -0.00186125,\n",
              "         0.02315824, -0.01485021],\n",
              "       [ 0.03485874, -0.08845596, -0.01677877, ..., -0.02750705,\n",
              "         0.03230237, -0.00820087]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3tvUYSOY0op",
        "outputId": "5f612333-929d-4e57-d3b8-ecc2ac5092ef"
      },
      "source": [
        "embed_samples[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu5mF1qaZSCi"
      },
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name='USE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bsf7C1Vub1A7",
        "outputId": "fc0cb391-b229-4dbb-af17-785935d15c35"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               #layers.Dense(64, activation='relu'),\n",
        "                               layers.Dense(1, activation='sigmoid', name='output_layer')\n",
        "], name='model_6_USE')\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5BoJu2McfIF",
        "outputId": "8ae3293a-1ee1-49c7-cfd2-99b8be00d56e"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'tf_hub_sentence_encoder')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210715-065855\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 25ms/step - loss: 0.6519 - accuracy: 0.7187 - val_loss: 0.6155 - val_accuracy: 0.7612\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.5837 - accuracy: 0.7865 - val_loss: 0.5651 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.5400 - accuracy: 0.7924 - val_loss: 0.5325 - val_accuracy: 0.7782\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.5108 - accuracy: 0.7987 - val_loss: 0.5107 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4904 - accuracy: 0.8006 - val_loss: 0.4963 - val_accuracy: 0.7861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68QnkZanc9kC",
        "outputId": "a20f0285-bd67-497f-f664-0b2398596016"
      },
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37161615],\n",
              "       [0.660447  ],\n",
              "       [0.843613  ],\n",
              "       [0.34317696],\n",
              "       [0.6505363 ],\n",
              "       [0.72014815],\n",
              "       [0.82206887],\n",
              "       [0.84212184],\n",
              "       [0.73909146],\n",
              "       [0.19805439]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o49uBrydJHq",
        "outputId": "70022f5d-b219-431e-dab2-7fb781a7c486"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDrf6rB8dVx9",
        "outputId": "ff1668fe-55d8-4f5f-d7f9-d835baa68d42"
      },
      "source": [
        "# Calculate model 6 preformance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'f1': 0.784763647084561,\n",
              " 'precision': 0.7868249339891382,\n",
              " 'recall': 0.7860892388451444}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UwXzYPHdjLi",
        "outputId": "a8cdbda6-1d51-44c2-be49-5ba1d29b889f"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1jr8XVsdkiy"
      },
      "source": [
        "#######################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THCNcqz4pBDW",
        "outputId": "5435e70f-29f9-4ac7-ee3c-d911bbb4f008"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               layers.Dense(64, activation='relu'),\n",
        "                               layers.Dense(1, activation='sigmoid', name='output_layer')\n",
        "], name='model_6_USE')\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk5QCIQLppH4",
        "outputId": "90eadd2d-64b8-4634-c641-b74874d33671"
      },
      "source": [
        "# Fit the model\n",
        "history_model_6 = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'tf_hub_sentence_encoder')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210715-065914\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 19ms/step - loss: 0.5087 - accuracy: 0.7774 - val_loss: 0.4489 - val_accuracy: 0.8045\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 12ms/step - loss: 0.4140 - accuracy: 0.8151 - val_loss: 0.4360 - val_accuracy: 0.8150\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4003 - accuracy: 0.8229 - val_loss: 0.4301 - val_accuracy: 0.8110\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3919 - accuracy: 0.8257 - val_loss: 0.4263 - val_accuracy: 0.8215\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3851 - accuracy: 0.8297 - val_loss: 0.4274 - val_accuracy: 0.8176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04t5YqKkqMvW",
        "outputId": "b9afb22d-d82c-4c91-e4b9-11aaf5c63b5d"
      },
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1874645 ],\n",
              "       [0.7732298 ],\n",
              "       [0.98900676],\n",
              "       [0.22109935],\n",
              "       [0.7139187 ],\n",
              "       [0.7011268 ],\n",
              "       [0.9821463 ],\n",
              "       [0.9741251 ],\n",
              "       [0.9311039 ],\n",
              "       [0.08880273]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRyN2PnsqWP3",
        "outputId": "a8a60d15-c5e7-4a1c-aee8-17ddb7b081c5"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sl-ARLHqhEv",
        "outputId": "2ffd601b-f73c-4bc5-fd5d-7a6facb01b5b"
      },
      "source": [
        "# Calculate model 6 preformance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.75853018372703,\n",
              " 'f1': 0.8159820561172786,\n",
              " 'precision': 0.8202616926815424,\n",
              " 'recall': 0.8175853018372703}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oDqtpS8qwAb",
        "outputId": "fa6715ad-9277-4d43-fcda-12c9fd30bd68"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kliHRUisqx6O"
      },
      "source": [
        "#######################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nQDGyJ6wWpx"
      },
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when you don't have a large dataset.\n",
        "\n",
        "To see how model performs on a smaller dataset, let's replicate `model_6` except we'll train it on the 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTZm61bjwrno"
      },
      "source": [
        "# ## NOTE: Making data splits like below leads to data leakage (model_7 trained on )10% data, outperforms model_6 trained on 100% data)\n",
        "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "\n",
        "# # Create subset of 10% of the trainif data\n",
        "# train_10_percent = train_df_shuffled[['text', 'target']].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_percent['text'].to_list()\n",
        "# train_labels_10_percent = train_10_percent['target'].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3X0QvH5KM7M"
      },
      "source": [
        "> **NOTE:** Be *very* careful when creating training/val/test splits that you don't leak data across the dtaasets, otherwise your model evaluation metrics will be wrong. If something looks good to be true (a model trained on 10% of data outperforming the same model trained on 100% of data) trust your gut and go back through to find where the error may lie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P12KuJ_CHvgf"
      },
      "source": [
        "# Making a better dataet split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtOFTT30I1yB",
        "outputId": "bf11be23-b127-4592-b410-584ab8b8e771"
      },
      "source": [
        "# Check the number of each label in the updated training data subset\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpa1G9PExrEe"
      },
      "source": [
        "# Check the number of targets in our subset of data\n",
        "#train_10_percent['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImyX5SxVx6ns",
        "outputId": "acd18697-aa44-41d7-e88a-c141db162e31"
      },
      "source": [
        "train_df_shuffled['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ICrrcPPx9zR"
      },
      "source": [
        "To recreate a model the same as a previous model you've created you can use the `tf.keras.model.clon_model()` method, see more here: https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98OAP7m8ygzx",
        "outputId": "6487d467-e9c8-40d0-e7c5-d80806f379e8"
      },
      "source": [
        "# Let's build a model the same as model_6\n",
        "# model_7 = tf.keras.models.clone_model(model_6) - Alternatively\n",
        "model_7 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               layers.Dense(64, activation='relu'),\n",
        "                               layers.Dense(1, activation='sigmoid', name='output_layer')\n",
        "], name='model_7_USE')\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PWpGzKG-RnW",
        "outputId": "c630817e-2925-4df1-807a-fbabdcb5e8c3"
      },
      "source": [
        "# Fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'tf_hub_sentence_encoder_10_percent_correct_split')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20210715-065937\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 3s 91ms/step - loss: 0.6655 - accuracy: 0.7051 - val_loss: 0.6421 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.5917 - accuracy: 0.8058 - val_loss: 0.5787 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.5150 - accuracy: 0.8146 - val_loss: 0.5271 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.4566 - accuracy: 0.8204 - val_loss: 0.4983 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.4196 - accuracy: 0.8321 - val_loss: 0.4889 - val_accuracy: 0.7690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMDDAUGM_qNv",
        "outputId": "6b127847-5d17-4a56-ff78-e1d16dfdf8c1"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19366552],\n",
              "       [0.5624777 ],\n",
              "       [0.92549205],\n",
              "       [0.3935785 ],\n",
              "       [0.5415245 ],\n",
              "       [0.6993862 ],\n",
              "       [0.8932832 ],\n",
              "       [0.804708  ],\n",
              "       [0.8632446 ],\n",
              "       [0.14289515]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_fU2vDe_5fN",
        "outputId": "ceb0e7c8-871b-4dba-fa55-57d0cf33de13"
      },
      "source": [
        "# Turn pred probs into label\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2QLgVsUAEM9",
        "outputId": "8978dba0-ebfb-466f-d1e3-a211c29cfc36"
      },
      "source": [
        "# Evaluate model 7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.766802361272573,\n",
              " 'precision': 0.7708613696015271,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqxekFLNAUvm",
        "outputId": "1b119709-51cf-4bdf-d1b7-e7afac6a4c29"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.75853018372703,\n",
              " 'f1': 0.8159820561172786,\n",
              " 'precision': 0.8202616926815424,\n",
              " 'recall': 0.8175853018372703}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms6XL8GlAYy-"
      },
      "source": [
        "## Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "5sKtMABdLFVS",
        "outputId": "76c0574a-b208-42ad-bb0f-44b1620b2dfc"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({'0_baseline': baseline_results,\n",
        "                                  '1_simple_dense': model_1_results,\n",
        "                                  '2_lstm': model_2_results,\n",
        "                                  '3_gru': model_3_results,\n",
        "                                  '4_bidirectional': model_4_results,\n",
        "                                  '5_conv1d': model_5_results,\n",
        "                                  '6_tf_hub_use_encoder': model_6_results,\n",
        "                                  '7_tf_use_encoder_10_percent': model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>77.559055</td>\n",
              "      <td>0.777749</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.773362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>78.346457</td>\n",
              "      <td>0.784778</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.781796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>77.427822</td>\n",
              "      <td>0.774732</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.772933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>75.853018</td>\n",
              "      <td>0.758177</td>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.757714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>81.758530</td>\n",
              "      <td>0.820262</td>\n",
              "      <td>0.817585</td>\n",
              "      <td>0.815982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_use_encoder_10_percent</th>\n",
              "      <td>76.902887</td>\n",
              "      <td>0.770861</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.766802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              accuracy  precision    recall        f1\n",
              "0_baseline                   79.265092   0.811139  0.792651  0.786219\n",
              "1_simple_dense               77.821522   0.780752  0.778215  0.775881\n",
              "2_lstm                       77.559055   0.777749  0.775591  0.773362\n",
              "3_gru                        78.346457   0.784778  0.783465  0.781796\n",
              "4_bidirectional              77.427822   0.774732  0.774278  0.772933\n",
              "5_conv1d                     75.853018   0.758177  0.758530  0.757714\n",
              "6_tf_hub_use_encoder         81.758530   0.820262  0.817585  0.815982\n",
              "7_tf_use_encoder_10_percent  76.902887   0.770861  0.769029  0.766802"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "0v63HGtlMYQJ",
        "outputId": "d7af555f-5108-41d1-9276-109ddb5c5d13"
      },
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results['accuracy'] = all_model_results['accuracy']/100\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.777749</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.773362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.784778</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.781796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.774732</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.772933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.758177</td>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.757714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.817585</td>\n",
              "      <td>0.820262</td>\n",
              "      <td>0.817585</td>\n",
              "      <td>0.815982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_use_encoder_10_percent</th>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.770861</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.766802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             accuracy  precision    recall        f1\n",
              "0_baseline                   0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense               0.778215   0.780752  0.778215  0.775881\n",
              "2_lstm                       0.775591   0.777749  0.775591  0.773362\n",
              "3_gru                        0.783465   0.784778  0.783465  0.781796\n",
              "4_bidirectional              0.774278   0.774732  0.774278  0.772933\n",
              "5_conv1d                     0.758530   0.758177  0.758530  0.757714\n",
              "6_tf_hub_use_encoder         0.817585   0.820262  0.817585  0.815982\n",
              "7_tf_use_encoder_10_percent  0.769029   0.770861  0.769029  0.766802"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "2XknOO-JNkNJ",
        "outputId": "40e3a0db-af51-4315-a7fc-cf9197ca1b33"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind='bar', figsize=(10,7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAIlCAYAAAD2VGFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZyWdb3/8fd7WEQEUXFEFBBUBMYFUSRzyXIpPSZaehLTtE7FsUJN2yyPS2aZZlqUv3MwM8vlkJkZrmSlcMolQENhAEUkxAVHRVARYeDz++O6Rm6HgRl0mOs7XK/n48GD+1rmng/3g7nnfX9XR4QAAACAlFQVXQAAAADQGCEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkdCzqG2+77bbRv3//or49AABAi02bNu3liKguuo4yKSyk9u/fX1OnTi3q2wMAALSY7X8VXUPZ0N0PAACA5BBSAQAAkBxCKgAAAJJT2JhUAACA9mzatGnbdezY8VpJe4iGvw21WtKM+vr6L+y7774vNXUDIRUAAOA96Nix47Xbb7/9kOrq6sVVVVVRdD3tyerVq11XV1fz4osvXitpZFP3kPoBAADemz2qq6uXElA3XFVVVVRXVy9R1grd9D1tWA8AAMCmpIqA+t7lr906syghFQAAAMlhTCoAAEAr6H/uXfu25vPN/+HR01rz+dobWlIBAACwXitXrmzz70lIBQAAaMcOP/zwXXbfffchu+666+5XXHHFtpJ06623bllTUzNk0KBBNR/84Ad3k6QlS5ZUnXDCCf132223mt12263m+uuv30qSunbtOqzhuX71q19tffzxx/eXpOOPP77/pz/96X577bXX4C996Ut97r///q5777334CFDhtQMGzZs8PTp0zeTpPr6eo0ePbrPwIEDd99tt91qvv/97283YcKE7ocffvguDc/7hz/8YcsjjjhiF20AuvsBAADasZtuuml+r169Vr3xxhseNmxYzYknnvjamDFj+j/wwAOzBw8evGLRokUdJOncc8/tveWWW6568sknayWprq6uQ3PP/cILL3R+9NFHZ3fs2FGvvvpq1ZQpU2Z36tRJt99+e/dvfvObfSZOnPj0j3/84+oFCxZ0rq2tndmpUyctWrSoQ3V19aqzzjqr3/PPP99xhx12qL/uuut6fu5zn3t5Q/5dhFQAAIB27LLLLut11113bSVJL774YqexY8dWjxgx4vXBgwevkKRevXqtkqTJkydvOX78+HkNX1ddXb2quef+5Cc/ubhjxywuvvrqqx1OPPHEAfPnz+9iO1auXGlJ+utf/7rl6aefXtepUydVfr9PfepTr/ziF7/Y5itf+corjz76aLfbbrvtmQ35dxFSAQAA2qk777yz+6RJk7pPnTp1dvfu3VePGDFi0LBhw5bNmTOnS0ufw/Y7j9966y1XXuvWrdvqhsff+ta3djzkkENev++++56eM2dO50MPPXTQ+p73S1/60itHH330rl26dIljjjlmcUOIbSnGpAIAALRTr732WocePXqs6t69++rHHnusy/Tp07dYvnx51T/+8Y/us2fP7ixJDd39hxxyyNKrrrpqu4avbeju79mz58pHH320y6pVq/THP/5x63V9r6VLl3bo06fPCkkaN27ctg3nDzvssKXjxo3btmFyVcP369+//8pevXqt/PGPf9x79OjRG9TVL9GSCgAA0CqKWDLq+OOPX3LNNddU77zzzrvvvPPOy4cOHfrmdtttVz927Nj5n/jEJ3ZdvXq1evbsufLBBx986tJLL33hc5/7XL+BAwfuXlVVFd/5zneeP+2001777ne/+9yxxx676zbbbFM/dOjQZW+++WaTjZjf+ta3XvzCF74w4LLLLtvhiCOOeK3h/Nlnn1335JNPbjZ48ODdO3bsGKeddlrdd77znTpJGjVq1CtXX311x3322Wf5hv7bHFHMRgnDhw+PqVOnFvK9AQBoUxf1aOb6krapA++Z7WkRMbzy3PTp0+cPHTp0g1sIy+TUU0/tN2zYsGVnn312k6/T9OnTtx06dGj/pq7RkgoAAIBWt/vuuw/ZfPPNV48bN+7Z9/L1hFQAAN6H/ufe1ew985uZwrLnr/ds9jluubS+2XuGzJ7V7D1AW5k5c+b7+g/JxCkAAAAkZ9NvSW1uHJDEWCAAAIDE0JIKAACA5LQopNo+0vYc23Ntn9vE9X6277f9mO3Hbf9b65cKAACAsmi2u992B0lXSzpC0kJJU2xPiIjaitv+S9ItEfHftmsk3S2p/0aoFwAAIE0X9di3dZ9vSZuvuypJkydP7nrdddf1vP7665uclT9//vxOp59+et977713XlPXW0tLxqSOkDQ3IuZJku3xko6VVBlSQ9KW+eMekp5vzSIBAADw3tTX16tjx5ZPQ/rQhz607EMf+tCydV3v37//yo0dUKWWdffvKKkySS/Mz1W6SNIpthcqa0U9o6knsj3a9lTbU+vq6t5DuQAAAGgwZ86czgMGDNh95MiRA3beeefdjzzyyJ1ff/31qh133HHPL33pSzvW1NQMue6667a+7bbbttx7770H19TUDDnqqKN2XrJkSZUkTZo0qeuwYcMGDxo0qGbPPfccsnjx4qo777yz+0c+8pFdJemuu+7qNnjw4JrBgwfXDBkypGbx4sVVc+bM6Txw4MDdJWnZsmU+4YQT+u+22241Q4YMqbnjjju6S9LYsWN7fvSjH93l4IMPHrjTTjvtcfrpp/fZ0H9ba02cOknS9RHRR9K/SbrB9lrPHRHXRMTwiBheXV3dSt8aAACgvObPn99lzJgxL82bN29m9+7dV//oRz+qlqSePXvW19bWzjrmmGNe/8EPftB78uTJT9bW1s7aZ599ln3ve9/rtXz5cp988sm7/OQnP1kwZ86c2kmTJs3p1q3b6srn/vGPf7z92LFj/zV79uzahx9+eHbj65dddtl2tvXkk0/W3nzzzfNGjx7df9myZZak2trarrfffvu8WbNmzZwwYcLWc+fO7bQh/66WhNTnJPWtOO6Tn6v0eUm3SFJEPCSpi6RtN6QQAAAAbLjtt99+xUc/+tE3Jekzn/nMKw8++GA3STr11FMXS9IDDzywxdNPP91lxIgRgwcPHlwzfvz4ngsWLOj8+OOPd9luu+1WHnLIIcskaZtttlndqdO7c+T+++//xte//vW+l1xyyXYvv/xyh8bXH3zwwW6f+cxnXpGkYcOGLd9hhx1WPPHEE10k6aCDDlras2fPVV27do1dd911+dNPP73Zhvy7WhJSp0gaaHuA7c6SRkma0OieBZIOkyTbQ5SFVPrzAQAANjLbTR537959tSRFhA466KCls2fPrp09e3bt008/PfOWW275V0ue+wc/+MGL11577b/eeuutqoMPPnjwY4891sz+aWt07tw5Gh536NAhVq5c6fXd31izo2gjot72GEkTJXWQdF1EzLR9saSpETFB0tck/cL22comUX02ImLdz9p6mtuOrrmt6KSWbUf3xGlPtLQkAACANvPCCy90/vOf/7zF4Ycf/uZNN920zQEHHPBGbW1t14brH/7wh9/82te+1m/GjBmb7bHHHm8vXbq0av78+Z322muv5S+99FKnSZMmdT3kkEOWLV68uKpxd/7MmTM3GzFixFsjRox4a9q0aV1nzJjRZcSIEe9MqjrwwAPfuPHGG7cZOXLk648//vhmL7zwQue99tpr+SOPPNJV71OLpnpFxN3KJkRVnrug4nGtpAPfbzEAAADtVkFLRvXv33/5z372s+1Gjx7ddeDAgcu//vWv11177bXbNVzfYYcd6seNGzd/1KhRO69YscKSdOGFFz631157vX3TTTc9feaZZ/Zbvnx5VZcuXVZPnjz5ycrnvvzyy7d78MEHt7QdgwYNeuuEE05YsmDBgnf6/L/5zW++dOqpp+6022671XTo0EHjxo2bv/nmm7dKQ6XbqMFzLcOHD4+pU6e+7+dpviX1080+x54D+jV7zy2X1q/3+pDZs5p9DgDApqe530NS87+LWuP3kMTvoo3J9rSIGF55bvr06fOHDh36clE1Sdns/o9//OMDn3rqqZlF1vFeTZ8+fduhQ4f2b+payxfNAlBOF/VowT1LNn4dAIBSIaQCJddW47ppBQKA1jdo0KAV7bUVtTmE1LKidQwAACSMkLoJatn4qOafp7nWsU1yxYPmwjvBHQCANkFIxXs2a/CQZu9Jqfu2NcI7y5UBANA2CKlAK2tv4R1NY+UQACgWIRUAALS9TXBuxJ6/3nPf1ny+J057opB1V8eOHdtz6tSpW/zmN79ZcM455+zQrVu3VRdffPGitq6DkAoAAFodO0K2vdWrVysi1KFDh6JLaRWEVAAA0G6VfYjVnDlzOn/sYx/bbdiwYW888cQTWxx77LGvTpw4casVK1b46KOPfu2qq656XpJ+/vOf9xw7dmwv2xoyZMhbt99++zM333xzjx/+8Ie9V65cWbX11lvX//a3v53Xt2/f5tcLbCOEVAAAgHZswYIFm/3yl798ZsmSJa/+7ne/2/rxxx+fFRE6/PDDd73nnnu6VVdX119xxRW9H3roodm9e/euX7RoUQdJOuKII94YNWrU7KqqKl155ZXbXnzxxdv/4he/WFj0v6cBIRUAAKAd692794rDDjvszdGjR/eZPHnyljU1NTWStGzZsqrZs2d3efTRR6uOOeaYxb17966XpF69eq2SpGeeeabzcccd16eurq7TihUrqvr27ft2kf+OxqqKLgAAAADvXdeuXVdLUkToq1/96guzZ8+unT17du2CBQtmnH322S+v6+vGjBnT78tf/vJLTz75ZO3Pf/7zf7399ttJ5UJaUgEALdKytYbf/9JcbKELvDdHHXXU0osuumiH0aNHv9qjR4/VzzzzTKfOnTvHxz72saUnnHDCruedd96L22+//apFixZ16NWr16rXX3+9Q79+/VZK0vXXX9+z6PobI6QCAAC0gqKWjGrwyU9+cunMmTO77LfffoOlrIX1pptuemb48OHLv/a1r71w8MEHD66qqoo99thj2e9///v555133vMnnXTSLj169Kg/6KCDXl+wYMFmRdbfGCEVAACgnRo0aNCKp556ambD8fnnn//S+eef/1Lj+84444xXzjjjjFcqz51yyimvnXLKKa81vvfMM898RdIrknTllVc+vxHKbpGkxh4AAAAAEiEVAAAACSKkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHJagAgAAaAWzBg/ZtzWfb8jsWc2uu3rJJZdsd91111UPHDhw+aJFizrV1tZ2Pffcc5+7+OKLF7VmLUUgpAIAALRTv/zlL6v//Oc/P9mlS5eYO3du51tvvXXromtqLXT3AwAAtEOf/vSn+y1cuHCzo446auC11167zSGHHLKsU6dOUXRdrYWWVAAAgHbo5ptvXjBp0qQekyZNerJ37971RdfT2mhJBQAAQHIIqQAAAEgOIRUAAADJYUwqAABAK2jJklEby4IFCzrut99+NW+++WYH2zFu3Lhes2bNmrHNNtusLqqm94uQCgAA0E4999xzTzQ8XrRo0eNF1tLa6O4HAABAcgipAAAASA4hFQAA4L1ZvXr1ahddRHuVv3brHDNLSAUAAHhvZtTV1fUgqG641atXu66uroekGeu6p0UTp2wfKemnkjpIujYiftjo+lWSPpIfdpW0XURs9Z6qBgAAaAfq6+u/8OKLL1774osv7iEa/jbUakkz6uvrv7CuG5oNqbY7SLpa0hGSFkqaYntCRNQ23BMRZ1fcf4akYe+nagAAgNTtu+++L0kaWXQdm6qWpP4RkuZGxLyIWCFpvKRj13P/SZL+tzWKAwAAQDm1JKTuKOnZiuOF+bm12N5J0gBJf33/pQEAAKCsWnv8xChJt0bEqqYu2h5te6rtqXV1da38rQEAALCpaElIfU5S34rjPvm5pozSerr6I+KaiBgeEcOrq6tbXiUAAABKpSUhdYqkgbYH2O6sLIhOaHyT7cGStpb0UOuWCAAAgLJpNqRGRL2kMZImSpol6ZaImGn7YtuVM9pGSRofEbFxSgUAAEBZtGid1Ii4W9Ldjc5d0Oj4otYrCwAAAGXGwrMAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJKdFIdX2kbbn2J5r+9x13PMp27W2Z9q+uXXLBAAAQJl0bO4G2x0kXS3pCEkLJU2xPSEiaivuGSjp25IOjIjFtrfbWAUDAABg09eSltQRkuZGxLyIWCFpvKRjG93zRUlXR8RiSYqIl1q3TAAAAJRJS0LqjpKerThemJ+rtJuk3Wz/3fbDto9s6olsj7Y91fbUurq691YxAAAANnmtNXGqo6SBkj4s6SRJv7C9VeObIuKaiBgeEcOrq6tb6VsDAABgU9OSkPqcpL4Vx33yc5UWSpoQESsj4hlJTyoLrQAAAMAGa0lInSJpoO0BtjtLGiVpQqN7blfWiirb2yrr/p/XinUCAACgRJoNqRFRL2mMpImSZkm6JSJm2r7Y9sj8tomSXrFdK+l+Sd+IiFc2VtEAAADYtDW7BJUkRcTdku5udO6Cisch6Zz8DwAAAPC+sOMUAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASE6LQqrtI23PsT3X9rlNXP+s7Trb/8z/fKH1SwUAAEBZdGzuBtsdJF0t6QhJCyVNsT0hImob3frbiBizEWoEAABAybSkJXWEpLkRMS8iVkgaL+nYjVsWAAAAyqwlIXVHSc9WHC/MzzV2vO3Hbd9qu29TT2R7tO2ptqfW1dW9h3IBAABQBq01ceoOSf0jYi9J90n6dVM3RcQ1ETE8IoZXV1e30rcGAADApqYlIfU5SZUto33yc++IiFci4u388FpJ+7ZOeQAAACijloTUKZIG2h5gu7OkUZImVN5gu3fF4UhJs1qvRAAAAJRNs7P7I6Le9hhJEyV1kHRdRMy0fbGkqRExQdKZtkdKqpf0qqTPbsSaAQAAsIlrNqRKUkTcLenuRucuqHj8bUnfbt3SAAAAUFbsOAUAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACS06KQavtI23Nsz7V97nruO9522B7eeiUCAACgbJoNqbY7SLpa0lGSaiSdZLumifu6SzpL0iOtXSQAAADKpSUtqSMkzY2IeRGxQtJ4Scc2cd/3JF0maXkr1gcAAIASaklI3VHSsxXHC/Nz77C9j6S+EXHX+p7I9mjbU21Praur2+BiAQAAUA7ve+KU7SpJV0r6WnP3RsQ1ETE8IoZXV1e/328NAACATVRLQupzkvpWHPfJzzXoLmkPSQ/Yni9pf0kTmDwFAACA96olIXWKpIG2B9juLGmUpAkNFyNiSURsGxH9I6K/pIcljYyIqRulYgAAAGzymg2pEVEvaYykiZJmSbolImbavtj2yI1dIAAAAMqnY0tuioi7Jd3d6NwF67j3w++/LAAAAJQZO04BAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5LQopNo+0vYc23Ntn9vE9dNtP2H7n7b/Zrum9UsFAABAWTQbUm13kHS1pKMk1Ug6qYkQenNE7BkRe0u6XNKVrV4pAAAASqMlLakjJM2NiHkRsULSeEnHVt4QEUsrDreQFK1XIgAAAMqmYwvu2VHSsxXHCyV9oPFNtr8i6RxJnSUd2tQT2R4tabQk9evXb0NrBQAAQEm02sSpiLg6InaR9C1J/7WOe66JiOERMby6urq1vjUAAAA2MS0Jqc9J6ltx3Cc/ty7jJR33fooCAABAubUkpE6RNND2ANudJY2SNKHyBtsDKw6PlvRU65UIAACAsml2TGpE1NseI2mipA6SrouImbYvljQ1IiZIGmP7cEkrJS2WdNrGLBoAAACbtpZMnFJE3C3p7kbnLqh4fFYr1wUAAIASY8cpAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkJwWhVTbR9qeY3uu7XObuH6O7Vrbj9v+i+2dWr9UAAAAlEWzIdV2B0lXSzpKUo2kk2zXNLrtMUnDI2IvSbdKury1CwUAAEB5tKQldYSkuRExLyJWSBov6djKGyLi/ohYlh8+LKlP65YJAACAMmlJSN1R0rMVxwvzc+vyeUn3NHXB9mjbU21Praura3mVAAAAKJVWnThl+xRJwyX9qKnrEXFNRAyPiOHV1dWt+a0BAACwCenYgnuek9S34rhPfu5dbB8u6TxJh0TE261THgAAAMqoJS2pUyQNtD3AdmdJoyRNqLzB9jBJ4ySNjIiXWr9MAAAAlEmzITUi6iWNkTRR0ixJt0TETNsX2x6Z3/YjSd0k/c72P21PWMfTAQAAAM1qSXe/IuJuSXc3OndBxePDW7kuAAAAlBg7TgEAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQnBaFVNtH2p5je67tc5u4/iHbj9qut31C65cJAACAMmk2pNruIOlqSUdJqpF0ku2aRrctkPRZSTe3doEAAAAon44tuGeEpLkRMU+SbI+XdKyk2oYbImJ+fm31RqgRAAAAJdOS7v4dJT1bcbwwP7fBbI+2PdX21Lq6uvfyFAAAACiBNp04FRHXRMTwiBheXV3dlt8aAAAA7UhLQupzkvpWHPfJzwEAAAAbRUtC6hRJA20PsN1Z0ihJEzZuWQAAACizZkNqRNRLGiNpoqRZkm6JiJm2L7Y9UpJs72d7oaR/lzTO9syNWTQAAAA2bS2Z3a+IuFvS3Y3OXVDxeIqyYQAAAADA+8aOUwAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5hFQAAAAkh5AKAACA5BBSAQAAkBxCKgAAAJJDSAUAAEByCKkAAABIDiEVAAAAySGkAgAAIDmEVAAAACSHkAoAAIDkEFIBAACQHEIqAAAAkkNIBQAAQHIIqQAAAEgOIRUAAADJIaQCAAAgOYRUAAAAJIeQCgAAgOQQUgEAAJAcQioAAACSQ0gFAABAcgipAAAASA4hFQAAAMkhpAIAACA5LQqpto+0Pcf2XNvnNnF9M9u/za8/Yrt/axcKAACA8mg2pNruIOlqSUdJqpF0ku2aRrd9XtLiiNhV0lWSLmvtQgEAAFAeLWlJHSFpbkTMi4gVksZLOrbRPcdK+nX++FZJh9l265UJAACAMnFErP8G+wRJR0bEF/Ljz0j6QESMqbhnRn7Pwvz46fyelxs912hJo/PDQZLmtNY/5H3aVtLLzd5VPrwua+M1aRqvS9N4XZrG67I2XpOmpfS67BQR1UUXUSYd2/KbRcQ1kq5py+/ZEranRsTwoutIDa/L2nhNmsbr0jRel6bxuqyN16RpvC7l1pLu/uck9a047pOfa/Ie2x0l9ZD0SmsUCAAAgPJpSUidImmg7QG2O0saJWlCo3smSC6P4EYAACAASURBVDotf3yCpL9Gc+MIAAAAgHVotrs/Iuptj5E0UVIHSddFxEzbF0uaGhETJP1S0g2250p6VVmQbU+SG4KQCF6XtfGaNI3XpWm8Lk3jdVkbr0nTeF1KrNmJUwAAAEBbY8cpAAAAJIeQCgAAgOQQUgEAAJAcQioAAAWwXWX7gKLrAFJV2olTtrtK+pqkfhHxRdsDJQ2KiDsLLi0JtrtGxLKi60iJ7a2VrQf8zqoYEfFocRUVy/aHmjofEZPbupYU2P7k+q5HxG1tVQvaD9uPRcSwoutIie0bIuIzzZ3Dpq9Nd5xKzK8kTZP0wfz4OUm/k1TqkJp/qr9WUjdJ/WwPlfSfEfHlYisrlu3vSfqspKclNXyyC0mHFlVTAr5R8biLpBHKfqbK+pocs55rIamUIdX261rzM7OWiNiyDctJ0V9sHy/pNtYXf8fulQe2O0jat6BaUKAyt6ROjYjhlZ9ibU+PiKFF11Yk248o25BhQsXrMiMi9ii2smLZniNpz4hYUXQtqbLdV9JPIuL4omtBevIPei9IukGSJZ0sqXdEXFBoYQXLQ/wWklZJekvZaxNlDO+2vy3pO5I2l9TQk2dJKyRdExHfLqo2FKPMLakrbG+u/BO+7V0kvV1sSWmIiGdtV55aVVQtCZkhaStJLxVdSMIWShpSdBEpsH20stagLg3nIuLi4ipKwshGjQD/bXu6pFKH1IjoXnQNqYiISyVdavtSAimkcofUCyXdK6mv7ZskHaisO7fsns27/MN2J0lnSZpVcE0puFTSY7ZnqOLDTESMLK6kYtn+mdZ041ZJ2ltSacfoNrD9P5K6SvqIsqEzJ0j6R6FFpeFN2ydLGq/s/81Jkt4stqTiOWsROFnSgIj4Xt4j0TsiSvt/JiK+bXtHSTvp3XMASjnevcxK290vSbZ7StpfWXfCwxHxcsElFc72tpJ+KulwZa/LnySdFRGvFFpYwWzPlDRO0hOSVjecj4hJhRVVMNunVRzWS5ofEX8vqp5U2H48Ivaq+LubpHsi4uCiayuS7f7K3lsOVBZS/y7pqxExv7iqimf7v5W9pxwaEUPyCZp/ioj9Ci6tMLZ/qGx79Vqt6cmLMjcKlFWZW1KlrCtusbLXocZ26T+p5UH95KLrSNCyiBhbdBGpyCcyfDQi+L+ytrfyv5fZ3kHSK5J6F1hPEvIwemzRdSToAxGxj+3HJCkiFtvuXHRRBfuEstV2GIJXcqUNqbYvk3SipJla0zIWkkodUm1fLukSZb9o75W0l6SzI+LGQgsr3v/ZvlTSBL27u7+U3dsRscr2TrY7M5lsLXfa3krSj5QNfwhl3f5oxPYFjNXVyvxDX8P8iGpV9NaU1DxJncQ8kdIrbXd/Plt7Lz6pvZvtf0bE3rY/Ienjks6RNJlVD3x/E6cjIsq63JJs/0bZRKkJqhhbGBFXFlZUYmxvJqlLRCwpupYU2V4QEf2KrqNI+TjdEyXtI+nXysYw/1dE/K7Qwgpk+/eShkr6i97dKHBmYUWhEKVtSRWf1Nal4f/E0ZJ+FxFLGs30L6vPR8S8yhO2dy6qmEQ8nf+pksQM5Qr55MP+yn+e8qFEvym0qILYXrquS8qWGiq1iLjJ9jRJhyl7TY6LiLJPVp2Q/0HJlbkllU9qTcgHrB+nrLt/hLJll+6MiA8UWljBbD8aEfs0OjctIlhgGu9i+wZJu0j6p9496aOU7y22F0jaLyIWNXHt2YjoW0BZhbO9zfquR8SrbVVLivIlIvtFxJyia0FxytySyie1JkTEufm41CX5uMM3VeLJDrYHK1vvskejbS+3VMUamGVk+w6tvZPQEklTJY2LiOVtX1UShkuqYfegd/xG2VJCa4VUSTe3cS0pmabs58eS+imbxGtlDQMLJA0orrRi2T5G0hWSOksaYHtvSRczu798StuSinVr3FUpqcxdlccqa1keqXd/qHld0viIeLCQwhJg+6eSqiX9b37qRElLlf3i3bKs+2zb/p2kMyPihaJrQfps/0LSHyLi7vz4KGVd/v9ZbGXFyYc/HCrpAXY+LLfStaTaviUiPmX7CTWxn3RE7FVAWclYV1elstaQ0omIP0r6o+0PRsRDRdeTmAMareV4h+0pEbFfvq5sWW0rqdb2P8TGD+/IW97/V9IfI6L0i/hX2D8ivthwEBH35L1ZZbayifkQZV/xoJRKF1KV7aAkZTPXsTa6Kpv2iTx4sTTXGt1s94uIBZJku5+kbvm1Mi9LdVHRBSTqCmWt7ZfanqJs56k7SzwspMHztv9LUsN7ycmSni+wnhTMtP1pSR1sD5R0pqTS9lqVGd39eBe6KpvG0lxrs/1vkv5H2Qx/KxtD92VJD0j6YkT8pLjqimW7l6SGVuZ/RMRLRdaTknxN0EMlfVHSkRGxZcElFSqfQHWhpA/lpyZL+m6ZJ07Z7irpPEkfzU9NlHQJH2jKp3Qh1fbrWtPN39CX0DB4PXjD9P3K9mCnq7KC7ZkRsbvtayXdGhH32p5e5pAqvbMO6OD8cE7lLxHbR0TEfcVUVhzbn1K2kP8Dyt5XDpb0jYi4tci6UpDP2D5Ga9YFvTMizii2qjTY7q7sd9AbRdcCpKJ0IRXrZ/uQps6XeY96iaW53oumlu0qA9vTJR3R0Hqa7yD0Zz7Q+BZlPzv3SvqtpEkRUfpxhrb3VDbmv2FJqpclnRYRM4qrqli275P07xHxWn68tbKJqh8rtjK0tTKOSX2H7YMkDYyIX9neVlL3iHim6LqKFBGTbO+k7HX5c97t0qHouorG0lzvSVl3gahq1L3/irIND8rul5JOiohVzd5ZLuMknRMR90uS7Q9LukbSAUUWVbBtGwKqJEXEYtvbFVkQilHakGr7QmWThAZJ+pWy9dhulHRgkXUVzfYXJY1W9ql+F0k7Kht3eFiRdRWl0dqoDecqD29ru2ranbJ209xre6LevTTX3QXWk4SImGj7ANv9xfJ2lbZoCKiSFBEP2N6iyIISsLrRpMydVN73k1IrbUiV9AlJwyQ9KkkR8Xw+JqjsvqKsS+4RSYqIp0r+CfaY9VwLEVLRSER8w/bxWvOB95qI+EORNaWA5e3WaZ7t8yXdkB+fomzb7jL7jqS/2Z6kNeO6RxdbEopQ5pC6IiLCdkgSn1zf8XZErGhoLbTdUSX+BBsRn2vJfbZPi4hfb+x6UmF7hLJJHlNs10g6UtLshgXJc/MLKS4BEfF7Sb8vuo7EsLxd0/5D0neVfeANSf+Xnysl21WSeiibWLd/fvqrEfFycVWhKKWdOGX765IGSjpC0qXK3hRujoifFVpYwfJxl69JOlXSGcqWFKqNiPMKLSxxZZoklA+VOUrZh9z7JH1A0v3KfpYmRsT3CyyvMLb/FhEHNVpBRGLlEEksb4eWsz01IoYXXQeKV9qQKmVL5Chbh83KfrmWbrmcxvJPsZ9Xxesi6VpaP9bP9mMN2/dt6vLd2vaWtJmkFyX1iYil+fJCj5R91zY0jeXtmsZM9rXlq6m8rGwViHd2Jyvz2rFlVdru/rx7/68RcZ/tQZIG2e4UESuLrq1I+ZIwv8j/oOXKFOLr8xnay2w/HRFLJSki3rLNkkL2DRHxmebOldBFRReQKGayr+3E/O+vVJwLSTsXUAsKVNqQqmxXj4PzT633Spqq7Afj5EKrKkjeOrbOoEXrWLPKtNzSCttdI2KZpH0bTtruIfbXlqTdKw/ycd37ruPe0siXt2MnrrUxk72RiBhQdA1IQ5lDqiNime3PS/rviLjc9j+LLqpAH8//bvjkWjnTtNRvmLYHK1uK65HK3WBsHxkR9+aHfy+kuGJ8KCLelt5peW/QSdJpxZRUPNvfVjYreXPbSxtOS1qhbN3LUmtiJ66f2WYnrmz7T2ayV8jX5z5HUr+IGG17oKRBEXFnwaWhjZV2TKrtx5RNCrpK0ucjYqbtJyJiz4JLK1RTYyvLNCmoMdtnKgvus5SNpzsrIv6YXyvt64J1s31pRHy76DpSw05c65ZvJtMwk/3hss9kt/1bSdMknRoRe+Sh9cGI2Lvg0tDGyrwLylmSvi3pD3lA3VnZDOWys+0DKw4OULn/n3xR0r4RcZykD0s63/ZZ+bUydfGj5f6RD32QJNneyvZxRRaUCHbiWrfNJL0qaamkGtsfKrieou0SEZdLWilJ+dAi3m9LqLTd/RExWdm41IbjeZLOLK6iZHxe0nUVv2RfU4nX7FP2i/UNSYqI+fmWhbfm48Z400RTLqxcvD8iXsuX7bq9wJpS0NROXPcUWE8SbF+m7LWYqTVjukMVv59KaEW+WkjDOua7qGJFCJRHaUNq3tX0TWWTHLo0nI+IQwsrKgERMU3S0IaQGhFLKq+XbdF6SYts7x0R/5SkiHjD9sclXSep1ENDsE5NtQ6W9r22Qb4T1yclHZSfYieuzHHKxlsSwta4UNmE5r62b1K2e9tnC60IhSjzmNQ/KVuD7euSTlc24aMuIr5VaGGJK9s4TNt9lC259GIT1w6MiDJNmEIL2L5OWQ/E1fmpr0jaJiI+W1hRCbA9QNILEbE8P95cUq+ImF9oYQWzfY+ydVLfaPbmErHdU9k4XYtxuqVV5pA6LSL2tf14w/JKtqdExH7NfW2ZlWnReuC9yNdgPl/S4cq6K++T9P2IeHO9X7iJsz1V0gERsSI/7izp72V/z7X9e0lDJf1F797koNTDzypa3UPS32h1L6cyd0E1LNr/gu2jJT0vaZsC62kvyvmpBmihPIyea3uLsgfTRjo2BFRJiogVeVAtuwn5H+Rs/z9Ju2rN+OX/tH14RHxlPV+GTVCZQ+ol+bjLr0n6maQtJZ1dbEntApOFgPXIV8S4VlI3Sf1sD5X0nxHx5WIrK1yd7ZERMUGSbB+rbOvLUouIX+dDH/pFxJyi60nEoZKGNGzHbfvXyiaWoWRKG1IrFgVeIukjRdbSzjAGE1i/qyR9THnrWERMZ0khSdnY/5ts/zw/Xiip7FvFyvYxkq6Q1FnSANt7S7o4IkYWW1mh5krqJ+lf+XHf/BxKprRr1Nne2fYdtl+2/ZLtP+ZrpZaa7V62f5kP5pftmnxXLklSRIwprjqgfYiIZxudWlVIIQmJiKcjYn9JNZJqIuKAiHi64brtsu5WdpGkEcom2ylfSaTsv4u6S5pl+wHb90uqlbSl7Qm2GRpRIqVtSZV0s7LZt5/Ij0cpG//ygcIqSsP1kn6lbKs+SXpS2SoIvyyqIKCdeTbv8g/bnZRtHDKr4JqSsZ5Z7GdJKtPydg1WRsQS+10jqVav6+aSuKDoApCGMofUrhFxQ8Xxjba/UVg16dg2Im7J9yFXRNTbLn0rELABTpf0U0k7SnpO0p+ULUOF9SvrePeZtj8tqUO+R/2Zkh4suKZCRcSk9V23/VBEfLCt6kFxShdSbTfM4L/H9rmSxiubsX6ipLsLKywdb+br0zUMWN9f2bhdAM2w3UHSTyPi5KJraYfKunLIGcp6rt5W1sM3UdIlhVaUvi7N34JNQenWSbX9jLI3w6Y+tUdElHoskO19lK12sIekGZKqJZ0QEY8XWhjQTtj+m6RDK5dbQvNYg7lptn8WEWcUXUdKyrapTJmVriU1Iga05D7bR0TEfRu7ntRExKO2D5E0SFmQnxMRK5v5MgBrzJP093yCxzvrpEbElcWVlA7bBymbKDQjIv5UcYmVQ5p2YNEFAEUpXUjdAJcp2ymmFPLdPZqym21FxG1tWhDQfj2d/6lSNku51Gz/IyJG5I+/qGx87h8kXWh7n4j4ocTKIdggZR2/XDqE1HUr2w/BMeu5FpIIqUALRMR3i64hMZ0qHo+WdERE1Nm+QtLDkn5YTFlIle1eyiYeStJzEbGo0S2lX1+3LAip61aqwboR8bmiawDaM9s/iYiv2r5DTbx/lHhx9irbWytrWXZE1EnZ9rG264strV0oTYNJvpHB/0jqoWxlDEnqY/s1SV+OiEclKSJmFFQi2hghFe+Sz+y/UNJByn7R/k3Z7ievFFoYkL6GJe2uKLSK9PSQNE1Z2ArbvSPiBdvdVKIA1hzbXSNiWROXftrmxRTnemVbCD9SeTJfZeZXkoYWURSKU7rZ/ZJke7CkY1XRnSBpQkTMqrjntohY1zjNTZbt+yRNlnRjfupkSR+OiMOLqwrApsZ2V0m9IuKZomspUr7xw7WSukVEP9tDlQW1LxdcWpuz/VREDFzHtbkRsWtb14RilS6k2v6WpJOUrY+6MD/dR9mOU+MbBvGXle0ZEbFHo3NPRMSeRdUEtAe2n9B6hglFxF5tWA7aCduPSDpBWUPJsPzcWu/DZWB7rKRdJP1GUsPWwn0lnSrpGSbXlU8Zu/s/L2n3xssq2b5S0kwxiP9PtkdJuiU/PkHZ4tIA1u/j+d8Nu0s1dP+fopKNcceGiYhnG22LWspd/iLiTNtHae2ezqsjgs12SqiMLamzJX0sIv7V6PxOkv4UEYOKqSwNtl+XtIXW7B1dpTVrPUZEbFlIYUA70dSi9Cw+jnWxfaukKyX9XNIHJJ0laXhEjCq0MCABZWxJ/aqkv9h+Smu6E/pJ2lVS6bsSIqL06zoC75NtHxgRf88PDlD2YQ9oyunKJkftqKzV8E9a0xqPnO1rImJ00XWgbZWuJVWSbFcp2/GksjthSkSUsoulMdt7Seqvig8xLOYPtIztfSVdp2xWuyUtlvQfDcvnAGia7W3WdUnS9Ijo05b1oHilDKlYN9vXSdpL2fjchi7/iIj/KK4qoP2x3UOSImJJ0bUgXbYvl3SJpLck3avs/ffsiLhxvV+4CbK9StK/9O6lySI/3jEiOhdSGApDSMW72K6NiJqi6wDaG9unRMSNts9p6npEXNnWNSF9tv8ZEXvb/oSyyXfnSJocEaVbEzQfhndYRCxo4tqzEdG3gLJQIMZJobGHbBNSgQ23Rf5393X8AZrSMKzqaEm/K3nL+08kbb2Oa5e3ZSFIAy2peBfbh0iaIOlFSW8r3yWGNR4BoPXZ/qGk45R194+QtJWkOyPiA4UWljDbR0TEfUXXgY2PkIp3sT1XWXfTE1ozJlWNl+wC0DTbOyubrb2/svF0DykbYziv0MKQrHzC0JKIWJXvxLVlRLxYdF2pYkm38ijjElRYv7qImFB0EUA7drOkqyV9Ij8eJel/la2BCbyL7VMrHlde+k3bV9NuuPlbsCkgpKKxx2zfLOkOZd39kliCCtgAXSPihorjG21/o7BqkLr9Kh53kXSYpEdFSF0fuoBLgpCKxjZXFk4/WnEuJBFSgfWoWOPxHtvnShqv7GfnREls6YgmRcQZlce2t1L2fwcoPcakAkArsP2M1qzp2FhExM5tXBLaIdudJM0o6xbd+WY7+0fEg+u557aI+GQbloWCEFIhSbL9zYi43PbP1ERXSkScWUBZwCaHmcmoZPsOrXnPrZJUI+mWiDi3uKqKZfuxiBhWdB0oHt39aDAr/3tqoVUAm77LJBFS0eCKisf1kv4VEQuLKiYRf7F9vKTbgpa0UqMlFeuUd7t0i4ilRdcCbCpoJcKGsP1QRHyw6Draku3XlW2OsUrZ+rEN63VvWWhhaHPsOIV3sX2z7S1tbyFphqRaZiYDrYqWAWyILkUX0NYiontEVEVEp4jYMj8moJYQIRWN1eQtp8dJukfSAEmfKbYkACit0n2oceYU2+fnx31tjyi6LrQ9Qioa65TPLj1O0oSIWKkSvkkCrcF2U2tdzm/rOoB25v9J+qCkT+fHbyjbIAMlw8QpNDZO2S/R6ZIm295JEmNSgWbYbrxTmyV9JF/3UhExMv+bpXOwIcq4u9IHImIf249JUkQstt256KLQ9gipeJeIGCtpbMOx7QWSPlJxfFpE/LqI2oDE9ZFUK+larVkvdbikHxdZFNJne3tJI5T9v5kSES9WXC7jcKuVtjso78WzXS1pdbEloQh092O9IlNfceqswooB0jZc0jRJ50laEhEPSHorIiZFxKRCK0OybH9B0j8kfVLSCZIetv0fDdcjYkZRtRVorKQ/SNrO9vcl/U3SD4otCUVgCSpsEJbPAdbPdh9JV0laJGlkRPQruCQkzPYcSQdExCv5cU9JD5Z1x6kGtgdLOkxZj8RfImJWM1+CTRDd/dhQfKoB1iNfiP3fbR8txnOjea9Ier3i+PX8XOnY3qbi8CVJ/1t5LSJebfuqUCRCKjZUGQfxAxssIu6SdFfRdSBNts/JH86V9IjtPyprBDhW0uOFFVasaVoznrufpMX5460kLVC2JCJKhDGpaJbtz1Uc/r2wQgBg09E9//O0pNu1ppfqj5KeKaqoIkXEgIjYWdKfJR0TEdtGRE9JH5f0p2KrQxEYk4pm2V7AuDoAQFuw/URE7NncOWz66O6HJMn2urqXLKlXW9YCAGVh+341MdY/Ig4toJxUPG/7vyTdmB+fLOn5AutBQQipaNBL0seUjQGqZEkPtn05AFAKX6943EXS8ZLq13FvWZwk6UJly1BJ0uT8HEqGkIoGd0rqFhH/bHzB9gNtXw4AbPoiYlqjU3+3/Y9CiklEPov/LNvds8N4o+iaUAzGpAIAUJBGyy5VSdpX0tgyr5Nqe09Jv5HU8Nq8LOm0km5sUGq0pAIAUJzKZZfqlc3s/3yhFRVvnKRzIuJ+SbL9YUnXSDqgyKLQ9gipAAAUJCJY+3NtWzQEVEmKiAdsb1FkQSgGIRUAgALZPkBSf1X8To6I3xRWUPHm2T5f0g358SmS5hVYDwrCmFQAAApi+wZJu0j6p6RV+emIiDOLq6pYtreW9F1JBykbCvF/kr4bEY1Xn8EmjpAKAEBBbM+SVBP8MgbWwraoAAAUZ4ak7YsuIiW277O9VcXx1rYnFlkTisGYVAAA2pjtO5R1ZXeXVJuvjfp2w/WIGFlUbQnYNiJeaziIiMW2tyuyIBSDkAoAQNu7ougCErbadr+IWCBJtndSE1vHYtNHSAUAoI1FxKSW3Gf7oYj44MauJzHnSfqb7UnK1o89WNLoYktCEZg4BQBAomw/FhHDiq6jrdneVtL++eHDEfFykfWgGLSkAgCQrrK2JG0m6VVlOaXGtiJicsE1oY0RUgEAQDJsXybpREkzJa3OT4ckQmrJEFIBAGhj/v/t3UGInVcZxvH/U0nTDDgNYqHQKlS0ggiaWBUj4sLSKhqQ1o2tNbGrCjFduakbRTcVuggWl2p0oViaReuiCgUX1sFNmkKsVbAo6aJSXSTQ2NLW18XcmOmYNNnMec/k/n9wud/9zlk8zGZezvne8yU7q+rVS88kWx5mPl8E3n+Zfx9dwTwnVZKk8dbgf2+ceiv3DMgym+eBHd0h1M+VVEmSxrs6yV3AviR3bB6sqmOL75PDk/U7C5xI8iRvPjt2aV8Vu6wsUiVJGu8+4G5gN7B/01gBx4Ynmsdji4+WnEdQSZLUJMmhqnp4073LfV71ipVkF/Duqvpzdxb18ZlUSZL63HuBe2vDU0wkyX7gBPDE4veHk7iyuoTc7pckabAk1wM3ALuS7OF8F/8qsNIWbA7fBj4G/Bagqk4keU9nIPWwSJUkabzbgYPAjcBDnC9SzwAPNGWaxWtVdTp50+lb/7nYZF25LFIlSRqsqo4CR5PcWVWPXmxekgOLucvkj4uTD96W5H3AYeD3zZnUwMYpSZImleR4Ve3tzjFSkhXgW8Bti1u/Br5XVa/0pVIHi1RJkiaV5Omq2tOdYyZJflBV3+jOoa1nd78kSfNyJen/fbI7gMawSJUkaV659BTpymSRKknSYEk+nmR1cb0ryXeSPJ7kwSTXbpj6VFNEqZ1FqiRJ4/2I9XfUAxwBrgUeXNz78blJVXVofLTpubq8JDyCSpKk8a6qqtcX17ds6OD/XZITXaFmkmSlqs5eYOjI8DBq4UqqJEnjnUzytcX1M0luAUhyM/BaX6x+SfYleRZ4bvH7Q0l+eG68qn7SlU1jeQSVJEmDLZ47PQJ8CvgnsBc4tfgcrqpnGuO1SvIH4EvAY+eO30pysqo+2JtMo7ndL0nSYFV1Gji4aJ66ifX/xy9U1T96k82hqk5tei3qG11Z1MciVZKkJlV1BljaVdOLOJVkH1BJdgD3A39qzqQGbvdLkqRpJHkn649C3Mp6J/9vgPur6l+twTScRaokSZKmY3e/JEmaRpLvJ1lNsiPJk0leSvKV7lwazyJVkiTN5LbFs7pfAP4GvBf4ZmsitbBIlSRJMznX1P154JHFSQhaQnb3S5KkmfwqyXPAv4GvJ7kOeKU5kxrYOCVJkqaS5B3A6ap6I8kKsFpVL3bn0liupEqSpGkk+eqG641DPx2fRp0sUiVJ0kw+uuH6GuAzwHEsUpeO2/2SJGlaSXYDv6iqz3Zn0Vh290uSpJm9DNzUHULjud0vSZKmkeRx4Nw271XAB4Bf9iVSF7f7JUnSNJJ8esPP14G/V9ULXXnUxyJVkiRtG0nWquoT3Tm09XwmVZIkbSfXdAfQGBapkiRpO3ELeElYpEqSJGk6FqmSJKldkp2XO3VLg2gaFqmSJGkGawBJfnaJefcMyKIJeE6qJEmawdVJ7gL2Jblj82BVHVt8nxyeTC0sUiVJ0gzuA+4GdgP7N40VcGx4IrXynFRJkjSNJIeq6uFN93ZW1atdmdTDZ1IlSdJM7r3AvbXhKdTO7X5JktQuyfXADcCuJHs438W/Cqy0BVMbi1RJkjSD24GDwI3AQ5wvUs8ADzRlUiOfSZUkSdNIcmdVPfoW4weq6ujITOphkSpJkraNJMeram93Dm09G6ckSdJ24hunloRFqiRJ2k7cAl4SFqmSJGk7cSV1SVikSpKkdkkOJ3nXZUx9asvDaAo2TkmSpHZJTgMvA38Ffg48UlUv9aZSJ1dSJUnSDJ5n/YzU7wIfAZ5N8kSSA0ne3htNHVxJlSRJ7TYfLZVkB/A54MvArVV1XVs4tbBIlSRJ7ZI8XVV7LjK2UlVnR2dSL4tUSZLULsnNVfWX7hyah0WqJEmSRkeYhwAAACNJREFUpmPjlCRJkqZjkSpJkqTpWKRKkiRpOhapkiRJms5/AQ6jZ/xT0lvKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "RY-KLGz-NzkU",
        "outputId": "5ad7653f-961d-47b8-bdc7-302c5cc9a461"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values('f1', ascending=False)['f1'].plot(kind='bar', figsize=(10,7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc6b64b1990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH77GrqUO8K7"
      },
      "source": [
        "## Uploading our model training logs to TensorBoard.dev\n",
        "We can further inspect our model's performance using TensorBoard.dev: https://tensorboard.dev/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYordMSIExOf"
      },
      "source": [
        "# View TensorBoard logs of transfer learning modelling experiments (plus all of our other models)\n",
        "# Upload TensorBoard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs/ \\\n",
        "#   --name 'NLP Modelling Experiments ZTM TF Course Video' \\\n",
        "#   --description 'Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset' \\\n",
        "#   --one_shot  # exit the uploader once uploading is finished"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLyDgOm6G_Fq"
      },
      "source": [
        "Now I've ran the cell above, my modelling experiments are visible on TensorBoard.dev:\n",
        "https://tensorboard.dev/experiment/a7Bzg78pQJq6ZAVJ1r4gSg/\n",
        "\n",
        "> **Resource:** TensorBoard is great for quickly tracking experiments but for larger scale experiments and a whole bunch more tracking options, check out Weights & Biases: https://wandb.ai/site"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZe1bVuSI5uW"
      },
      "source": [
        "# See the previous TensorBoard Dev experiments you've run...\n",
        "# !tensorboard dev list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4GJ5IczIxZx"
      },
      "source": [
        "# If you need to delete an experiment from TensorBoard, you can run the following:\n",
        "# !tensorboard dev delete --experiment_id ZnGYxhwpRPysZsxUQqsD4Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znoZRnWiJRC_"
      },
      "source": [
        "## Saving and loading a trained model\n",
        "\n",
        "There are two main formats to save a model to in TensorFlow:\n",
        "1. The HDF5 format\n",
        "2. The `SavedModel` format (this is the default when using TensorFlow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc_GeVz2P55Z"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "# model_6.save('model_6.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0MZn-fxQKGy"
      },
      "source": [
        "# Load model with custom Hub Layer (required HDF5 format)\n",
        "# loaded_model_6 = tf.keras.models.load_model('model_6.h5',\n",
        "#                                             custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujetHneKUA4L"
      },
      "source": [
        "# How does our loaded model perform?\n",
        "# loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvbaAi0mUTD6"
      },
      "source": [
        "Now let's save to the `SavedModel` format... (see more on this here: https://www.tensorflow.org/tutorials/keras/save_and_load)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwtCxCLCUbbF"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model SavedModel format (default)\n",
        "# model_6.save('model_6_SavedModel_format')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkCU3w4pUkRT"
      },
      "source": [
        "# Load in a model from the SavedModel format\n",
        "# loaded_model_6_SavedModel_format = tf.keras.models.load_model('model_6_SavedModel_format')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JelMnob_U-sT"
      },
      "source": [
        "# Evaluate model in SavedModel format\n",
        "# loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SvfcY8AVMoC"
      },
      "source": [
        "# model_6_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFZYoVGuVkAc"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "- If our best model still isn't perfect, what examples is it getting wrong?\n",
        "- And of these wrong examples which ones is it getting *most* wrong (those will prediction probabilisties closest to the opposite class)\n",
        "\n",
        "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwIpADIrWce8",
        "outputId": "ef4fad2f-5257-4296-e74f-b11be5f88e70"
      },
      "source": [
        "# Download a pretrained model from Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-15 06:59:45--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.164.144, 142.250.73.208, 142.250.73.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.164.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   230MB/s    in 4.0s    \n",
            "\n",
            "2021-07-15 06:59:49 (228 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE2aJEj6W9nK",
        "outputId": "b668c085-7a3a-4b25-8c98-b39dab892730"
      },
      "source": [
        "# Import previously trained model from Google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model('08_model_6_USE_feature_extractor')\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 12ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJrII4OVXQz5",
        "outputId": "f428879e-e3cb-4ef5-8165-7fe8207aa3ef"
      },
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-eAExdMFVq6j",
        "outputId": "3e63c6d3-fd3c-4486-964b-9b0648c7d733"
      },
      "source": [
        "# Create DataFrame with validation sentences, validation labels and best performing model prediction labels + probabilities\n",
        "val_df = pd.DataFrame({'text': val_sentences,\n",
        "                       'target': val_labels,\n",
        "                       'pred': model_6_pretrained_preds,\n",
        "                       'pred_prob': tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "g-dtoHVvaZQd",
        "outputId": "ff5bf5b4-5f71-4a49-bda8-53f524d304ca"
      },
      "source": [
        "# Find the wrong predictions and sort by predcition probabilities\n",
        "most_wrong = val_df[val_df['target'] != val_df['pred']].sort_values('pred_prob', ascending=False)\n",
        "most_wrong.head(10)  # flase positives"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.814816\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.810840\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.803122\n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   0.766901\n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   0.766625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "P0iN7nEebQMv",
        "outputId": "13a010ab-3f15-4c11-887b-11396eb8ed6b"
      },
      "source": [
        "most_wrong.tail(10)  # these are false negatives"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>@DavidVonderhaar At least you were sincere ??</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.067303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>@willienelson We need help! Horses will die!Pl...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>Lucas Duda is Ghost Rider. Not the Nic Cage ve...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>going to redo my nails and watch behind the sc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>You can never escape me. Bullets don't harm me...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.049637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "536      @DavidVonderhaar At least you were sincere ??       1   0.0   0.067303\n",
              "408  @willienelson We need help! Horses will die!Pl...       1   0.0   0.055076\n",
              "294  Lucas Duda is Ghost Rider. Not the Nic Cage ve...       1   0.0   0.054603\n",
              "221  going to redo my nails and watch behind the sc...       1   0.0   0.054597\n",
              "59   You can never escape me. Bullets don't harm me...       1   0.0   0.049637\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   0.043918\n",
              "233                    I get to smoke my shit in peace       1   0.0   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   0.038998\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   0.037186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2P29O9za7QM"
      },
      "source": [
        "Let's remind ourselves of the target labels\n",
        "- 0 = not disaster\n",
        "- 1 = disaster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdOrLZa0bnT8",
        "outputId": "e91bbda4-5947-4548-978a-122f39af613a"
      },
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f'Target: {target}, Pred: {pred}, Prob: {pred_prob}')\n",
        "  print(f'Text:\\n{text}\\n')\n",
        "  print('----\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957678794861\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769821524620056\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523000478744507\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354544639587402\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272131681442261\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.814815878868103\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108396530151367\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.80312180519104\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7669008374214172\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.766625165939331\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXix40jcioYg",
        "outputId": "1c5b8260-d061-40b5-ece0-fb14f713f37c"
      },
      "source": [
        "# Check the false negatives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f'Target: {target}, Pred: {pred}, Prob: {pred_prob}')\n",
        "  print(f'Text:\\n{text}\\n')\n",
        "  print('----\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.06730346381664276\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05507579818367958\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05460338667035103\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.054597001522779465\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04963728412985802\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.043918490409851074\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.042086850851774216\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03899793699383736\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.038949452340602875\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03718579187989235\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXfgSiBYl0-a"
      },
      "source": [
        "## Making predictions on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuM8EOAXmUOZ",
        "outputId": "3c9d86e7-fe52-42dd-fdc8-d2104372e2d3"
      },
      "source": [
        "# Making predictions on the test dataset and visualizing them\n",
        "test_sentences = test_df['text'].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample]))  # our model expect list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f'Pred: {int(pred)}, Prob: {pred_prob}')\n",
        "  print(f'Text:\\n{test_sample}\\n')\n",
        "  print('-----\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 0, Prob: 0.11479883641004562\n",
            "Text:\n",
            "The only reason why player's now have an ego is cause MW3 had cod champs that's when eSports Blew up and now player's strictly look for ORGs\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.11554187536239624\n",
            "Text:\n",
            "? Stretcher in 5 min // Speaker Deck http://t.co/gXgJqQu3hU #pctool\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.23403656482696533\n",
            "Text:\n",
            "I so want to #win an ARC of WHEN WE COLLIDED Emery Lord's 2016 release! Open intl #TheStartofEmandYou #giveaway\n",
            " http://t.co/qcu4xO54wT\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.07968068867921829\n",
            "Text:\n",
            "@TypeEd been a bit inundated w. Illustrative work  BUT would love to catch up! ??????\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.9486056566238403\n",
            "Text:\n",
            "Severe Thunderstorm Warning until 10:30 PM local for Oklahoma County in OK. 60 Mph Wind Gusts And Half Dollar Size Hail. #okwx #myswc\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.9769763350486755\n",
            "Text:\n",
            "#Bestnaijamade: 16yr old PKK suicide bomber who detonated bomb in ... http://t.co/KSAwlYuX02 bestnaijamade bestnaijamade bestnaijamade beÛ_\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.2748015820980072\n",
            "Text:\n",
            "they're gonna fucking steal a nuclear fission reactor\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.5578176379203796\n",
            "Text:\n",
            "$GMCR no longe rGreen mountain now Red Mountain...stock annihilated after hours\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.631044328212738\n",
            "Text:\n",
            "lets hope this concert ends with zero casualties amen\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.08113159984350204\n",
            "Text:\n",
            "@Jethro_Harrup How many Hangarback Walkers does your opponent need to have before you board in Infinite Obliteration?\n",
            "\n",
            "-----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv0PmN0e-y5A"
      },
      "source": [
        "## The speed/score tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLvrnHT__X_4"
      },
      "source": [
        "# Let's make a function to measure the time of prediction\n",
        "def pred_timer(model, samples):\n",
        "  '''\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  '''\n",
        "  start_time = time.perf_counter()  # get start time\n",
        "  model.predict(samples)  # make predictions\n",
        "  end_time = time.perf_counter()  # get finish time\n",
        "  total_time = end_time-start_time  # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM7TDYhW_aMo",
        "outputId": "8513d56f-bb26-46d7-98ee-ea462137fde2"
      },
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
        "                                                            samples=val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.27089410899998256, 0.00035550408005247054)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMhvg-8f_btI",
        "outputId": "f0255b78-36d1-4efa-c9e0-f74e39a799a4"
      },
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01829862099998536, 2.401393832019076e-05)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-3NteVTBKOI",
        "outputId": "e1211024-17e5-4124-ee96-60da24015856"
      },
      "source": [
        "# Get results for pretrained GS model\n",
        "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
        "                                               y_pred=model_6_pretrained_preds)\n",
        "model_6_pretrained_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'f1': 0.8148082644367335,\n",
              " 'precision': 0.818446310697231,\n",
              " 'recall': 0.8162729658792651}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "iF77zPXgBg05",
        "outputId": "d48efc5b-4856-470b-a371-450326f9722a"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results['f1'], label='baseline')\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results['f1'], label='tf_hub_sentence_encoder')\n",
        "plt.legend()\n",
        "plt.title('F1-score versus time per prediction')\n",
        "plt.xlabel('Time per prediction')\n",
        "plt.ylabel('F1-score');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PHLrboVCMXp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}